{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grokkingDL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHKTMmqeOHBGHzQFvC+Cwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkmritunjay/machineLearning/blob/master/grokkingDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9r5cUuUg4kf"
      },
      "source": [
        "# Chapter 3:\n",
        "\n",
        "### Introduction to neural prediction: Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pml-QSb8hEYk",
        "outputId": "7c101b24-59ba-42fe-b663-16f71b563466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# simplest neural network\n",
        "\n",
        "weight =0.1\n",
        "\n",
        "def neural_network(input, weight):\n",
        "  prediction = input * weight\n",
        "  return prediction\n",
        "\n",
        "number_of_toes = [8.5, 9.5, 10, 9]\n",
        "input = number_of_toes[0]\n",
        "\n",
        "pred = neural_network(input, weight)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8500000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFyxYZcsh03J"
      },
      "source": [
        "#### What does this neural network do?\n",
        "It multiplies the input by a weight. It \"scales\" the input by a certain amount.\n",
        "\n",
        "The interface for a neural network is simple. It accepts an input variable as information and a weight variable as knowledge and outputs a prediction.\n",
        "\n",
        "It uses the knowledge in the weights to interpret the information in the input data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uYvUo4zjC37"
      },
      "source": [
        "### Making a prediction with multiple inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh_OYNDfhf9p",
        "outputId": "bb6b1860-5c1f-402c-8b93-705980fe735a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights = [0.1, 0.2, 0]\n",
        "\n",
        "def w_sum(a, b):\n",
        "  assert(len(a) == len(b))\n",
        "  output = 0\n",
        "\n",
        "  for i in range(len(a)):\n",
        "    output += a[i] * b[i]\n",
        "  return output\n",
        "\n",
        "def neural_network(inputs, weights):\n",
        "  prediction = w_sum(inputs, weights)\n",
        "  return prediction\n",
        "\n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "\n",
        "inputs = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "pred = neural_network(inputs, weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9800000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SOWtegaoQRX"
      },
      "source": [
        "#### Multiple inputs: What does this neural network do?\n",
        "\n",
        "It multiplies three inputs by three weights and take their sum. This is a weighted sum (dot product).\n",
        "\n",
        "This new neural network can accept multiple inputs at a time per prediction. Here we take each input and multiply it with its own weight to find local prediction and in the end we sum all the local predictions to get final prediction.\n",
        "\n",
        "The intuition behind how and why a dot product works is one of the most important parts of truly understanding how neural networks make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28YPFNL7yaan"
      },
      "source": [
        "#### A dot product gives you a notion of similarity between two vectors. Consider below examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8dsmgEkoIoa",
        "outputId": "c78c82b0-05c3-4a1b-e24f-ea19fbc94b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "a = [0, 1, 0, 1]\n",
        "b = [1, 0, 1, 0]\n",
        "c = [0, 1, 1, 0]\n",
        "d = [.5, 0, .5, 0]\n",
        "e = [0, 1, -1, 0]\n",
        "\n",
        "print('a * b: {}'.format(w_sum(a,b)))\n",
        "print('b * c: {}'.format(w_sum(b,c)))\n",
        "print('b * d: {}'.format(w_sum(b,d)))\n",
        "print('c * c: {}'.format(w_sum(c,c)))\n",
        "print('d * d: {}'.format(w_sum(d,d)))\n",
        "print('c * e: {}'.format(w_sum(c,e)))\n",
        "print('e * e: {}'.format(w_sum(e,e)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a * b: 0\n",
            "b * c: 1\n",
            "b * d: 1.0\n",
            "c * c: 2\n",
            "d * d: 0.5\n",
            "c * e: 0\n",
            "e * e: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz6r3J-xyh86"
      },
      "source": [
        "The highest weighted sum (sum(c,c)) is between vectors that are exactly identical. \n",
        "\n",
        "In contrast, because a and b have no overlapping weight, their dot product is zero. \n",
        "\n",
        "Most interesting weighted sum is between c and e, because e has a negative weight. This negative weight canceled out the positive similarity between them.\n",
        "\n",
        "But a dot product between e and itself would yield the number 2 (-ve * -ve turns +ve)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYKbMDk00DVw"
      },
      "source": [
        "### Multiple inputs: Complete runnable code (numpy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuB6F2M_w_vJ",
        "outputId": "9e24b1c6-3501-40aa-84ea-a71b4c7efb6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "weights  = np.array([0.1, 0.2, 0])\n",
        "\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
        "wlrec = np.array([0.65, 0.8, 0.8, 0.9])\n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "\n",
        "inputs = np.array([toes[0], wlrec[0], nfans[0]])\n",
        "\n",
        "def neural_network(inputs, weights):\n",
        "  prediction = np.dot(inputs, weights)\n",
        "  return prediction\n",
        "\n",
        "pred = neural_network(inputs,weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9800000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1RjOlfAKd7r"
      },
      "source": [
        "### Making a prediction with multiple outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exQBaiUO00Il",
        "outputId": "bf54f467-6bec-42dd-d8de-6155ef2baa3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights = [0.3, 0.2, 0.9]\n",
        "\n",
        "def ele_mul(input, weights):\n",
        "  output = [0,0,0]\n",
        "  assert(len(output) == len(weights))\n",
        "  for i in range(len(weights)):\n",
        "    output[i] = input * weights[i]\n",
        "  return output\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  pred = ele_mul(input, weights)\n",
        "  return pred\n",
        "\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "input = wlrec[0]\n",
        "\n",
        "pred = neural_network(input, weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.195, 0.13, 0.5850000000000001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCrJ815_Q8n5"
      },
      "source": [
        "### Multiple inputs and outputs: How does it work?\n",
        "\n",
        "It performs three independent weighted sums of the input to make three predictions. (3 weights going into each output node)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg4r31vFLRFU",
        "outputId": "5efa9e1a-e766-4f45-ef68-374c5bf29121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights = np.array([[0.1, 0.1, -0.3],\n",
        "          [0.1, 0.2, 0.0],\n",
        "          [0.0, 1.3, 0.1]])\n",
        "\n",
        "def w_sum(a, b):\n",
        "  assert(len(a) == len(b))\n",
        "  output = 0\n",
        "\n",
        "  for i in range(len(a)):\n",
        "    output += a[i] * b[i]\n",
        "  return output\n",
        "\n",
        "def vect_mat_mul(input, weights):\n",
        "  assert(len(input) == len(weights))\n",
        "  output = [0, 0, 0]\n",
        "  for i in range(len(input)):\n",
        "    output[i] = w_sum(input, weights[i])\n",
        "  return output\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  pred = vect_mat_mul(input, weights)\n",
        "  return pred\n",
        "\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0]) \n",
        "wlrec = np.array([0.65, 0.8, 0.8, 0.9]) \n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "pred = neural_network(input, weights)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.555, 0.9800000000000001, 0.9650000000000001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21PxGaFsTM-l"
      },
      "source": [
        "### Predicting on predictions\n",
        "\n",
        "We can also take the output of one network and feed it as input to another network. This results in two consecutive vector-matrix multiplications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2krtUXKSYXQ",
        "outputId": "01bb58e4-5257-41ea-9969-c548cf65e547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ih_wgt = [[0.1,0.2,-0.1],\n",
        "                 [-0.1,0.1,0.9],\n",
        "                 [0.1,0.4,0.1]]\n",
        "\n",
        "hp_wgt = [[0.3,1.1,-0.3],\n",
        "                 [0.1,0.2,0.0],\n",
        "                 [0.0,1.3,0.1]]\n",
        "\n",
        "weights = [ih_wgt, hp_wgt]\n",
        "\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0]) \n",
        "wlrec = np.array([0.65, 0.8, 0.8, 0.9]) \n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "def w_sum(a, b):\n",
        "  assert(len(a) == len(b))\n",
        "  output = 0\n",
        "\n",
        "  for i in range(len(a)):\n",
        "    output += a[i] * b[i]\n",
        "  return output\n",
        "\n",
        "def vect_mat_mul(input, weights):\n",
        "  assert(len(input) == len(weights))\n",
        "  output = [0, 0, 0]\n",
        "  for i in range(len(input)):\n",
        "    output[i] = w_sum(input, weights[i])\n",
        "  return output\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  hid = vect_mat_mul(input, weights[0])\n",
        "  pred = vect_mat_mul(hid, weights[1])\n",
        "  return pred\n",
        "\n",
        "prediction = neural_network(input, weights)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.21350000000000002, 0.14500000000000002, 0.5065]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m01X-PfiUsAG"
      },
      "source": [
        "### numpy version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agzo_3TcUX09",
        "outputId": "3f50ddb5-565a-41e7-eaf6-d94b91ca013c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ih_wgt = np.array([[0.1,0.2,-0.1],\n",
        "                 [-0.1,0.1,0.9],\n",
        "                 [0.1,0.4,0.1]])\n",
        "\n",
        "hp_wgt = np.array([[0.3,1.1,-0.3],\n",
        "                 [0.1,0.2,0.0],\n",
        "                 [0.0,1.3,0.1]])\n",
        "\n",
        "weights = np.array([ih_wgt, hp_wgt])\n",
        "\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0]) \n",
        "wlrec = np.array([0.65, 0.8, 0.8, 0.9]) \n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "\n",
        "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
        "\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  hid = np.dot(weights[0], input) # pay special attention here for position of vector and matrix during dot product\n",
        "  pred = np.dot(weights[1], hid)\n",
        "  return pred\n",
        "\n",
        "prediction = neural_network(input, weights)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.2135 0.145  0.5065]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz7C7Q7Kyk_U"
      },
      "source": [
        "## Chapter 4\n",
        "\n",
        "### Introduction to neural learning: Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb0Leo-Xyyz2"
      },
      "source": [
        "### Predict, Compare and learn\n",
        "\n",
        "Predict: How to use a neural network to make a prediction.\n",
        "\n",
        "Compare: Comparing gives a measurement of how much a prediction \"missed\" by.\n",
        "\n",
        "Learn: Learning tells each weight how it can change to reduce the error.\n",
        "\n",
        "### Simplest form of neural learning: Hot and Cold method.\n",
        "Hot and cold means wiggling the weights to see which direction reduces the error the most, moving the weights in that direction, and repeating until the error gets to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQDqnQgZVLRq",
        "outputId": "2a210281-7cd0-4496-f49c-3a520d034a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input = 0.5\n",
        "weight = 0.5\n",
        "goal_prediction = 0.8\n",
        "\n",
        "step_amount = 0.001\n",
        "\n",
        "for iteration in range(1101):\n",
        "  prediction = input * weight\n",
        "  error = (prediction - goal_prediction) ** 2\n",
        "  print(\"error: {}, prediction: {}\".format(error, prediction))\n",
        "  up_prediction = input * (weight + step_amount)\n",
        "  up_error = (up_prediction - goal_prediction) ** 2\n",
        "  down_prediction = input * (weight - step_amount)\n",
        "  down_error = (down_prediction - goal_prediction) ** 2\n",
        "  if(up_error > down_error):\n",
        "    weight = weight - step_amount\n",
        "  if(up_error < down_error):\n",
        "    weight = weight + step_amount\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error: 0.30250000000000005, prediction: 0.25\n",
            "error: 0.3019502500000001, prediction: 0.2505\n",
            "error: 0.30140100000000003, prediction: 0.251\n",
            "error: 0.30085225, prediction: 0.2515\n",
            "error: 0.30030400000000007, prediction: 0.252\n",
            "error: 0.2997562500000001, prediction: 0.2525\n",
            "error: 0.29920900000000006, prediction: 0.253\n",
            "error: 0.29866224999999996, prediction: 0.2535\n",
            "error: 0.29811600000000005, prediction: 0.254\n",
            "error: 0.2975702500000001, prediction: 0.2545\n",
            "error: 0.29702500000000004, prediction: 0.255\n",
            "error: 0.29648025, prediction: 0.2555\n",
            "error: 0.29593600000000003, prediction: 0.256\n",
            "error: 0.2953922500000001, prediction: 0.2565\n",
            "error: 0.294849, prediction: 0.257\n",
            "error: 0.29430625, prediction: 0.2575\n",
            "error: 0.293764, prediction: 0.258\n",
            "error: 0.2932222500000001, prediction: 0.2585\n",
            "error: 0.292681, prediction: 0.259\n",
            "error: 0.29214025, prediction: 0.2595\n",
            "error: 0.2916, prediction: 0.26\n",
            "error: 0.2910602500000001, prediction: 0.2605\n",
            "error: 0.29052100000000003, prediction: 0.261\n",
            "error: 0.28998225, prediction: 0.2615\n",
            "error: 0.28944400000000003, prediction: 0.262\n",
            "error: 0.2889062500000001, prediction: 0.2625\n",
            "error: 0.28836900000000004, prediction: 0.263\n",
            "error: 0.28783224999999996, prediction: 0.2635\n",
            "error: 0.28729600000000005, prediction: 0.264\n",
            "error: 0.2867602500000001, prediction: 0.2645\n",
            "error: 0.286225, prediction: 0.265\n",
            "error: 0.28569025, prediction: 0.2655\n",
            "error: 0.285156, prediction: 0.266\n",
            "error: 0.2846222500000001, prediction: 0.2665\n",
            "error: 0.28408900000000004, prediction: 0.267\n",
            "error: 0.28355624999999995, prediction: 0.2675\n",
            "error: 0.28302400000000005, prediction: 0.268\n",
            "error: 0.2824922500000001, prediction: 0.2685\n",
            "error: 0.281961, prediction: 0.269\n",
            "error: 0.28143025, prediction: 0.2695\n",
            "error: 0.28090000000000004, prediction: 0.27\n",
            "error: 0.2803702500000001, prediction: 0.2705\n",
            "error: 0.279841, prediction: 0.271\n",
            "error: 0.27931225, prediction: 0.2715\n",
            "error: 0.27878400000000003, prediction: 0.272\n",
            "error: 0.2782562500000001, prediction: 0.2725\n",
            "error: 0.277729, prediction: 0.273\n",
            "error: 0.27720225, prediction: 0.2735\n",
            "error: 0.27667600000000003, prediction: 0.274\n",
            "error: 0.2761502500000001, prediction: 0.2745\n",
            "error: 0.275625, prediction: 0.275\n",
            "error: 0.27510025, prediction: 0.2755\n",
            "error: 0.27457600000000004, prediction: 0.276\n",
            "error: 0.27405225000000005, prediction: 0.2765\n",
            "error: 0.273529, prediction: 0.277\n",
            "error: 0.27300624999999995, prediction: 0.2775\n",
            "error: 0.272484, prediction: 0.278\n",
            "error: 0.27196225000000007, prediction: 0.2785\n",
            "error: 0.27144100000000004, prediction: 0.279\n",
            "error: 0.27092025, prediction: 0.2795\n",
            "error: 0.27040000000000003, prediction: 0.28\n",
            "error: 0.2698802500000001, prediction: 0.2805\n",
            "error: 0.269361, prediction: 0.281\n",
            "error: 0.26884224999999995, prediction: 0.28150000000000003\n",
            "error: 0.268324, prediction: 0.28200000000000003\n",
            "error: 0.2678062500000001, prediction: 0.28250000000000003\n",
            "error: 0.267289, prediction: 0.28300000000000003\n",
            "error: 0.26677224999999993, prediction: 0.28350000000000003\n",
            "error: 0.266256, prediction: 0.28400000000000003\n",
            "error: 0.26574025000000007, prediction: 0.28450000000000003\n",
            "error: 0.265225, prediction: 0.28500000000000003\n",
            "error: 0.26471025, prediction: 0.28550000000000003\n",
            "error: 0.264196, prediction: 0.28600000000000003\n",
            "error: 0.26368225000000006, prediction: 0.28650000000000003\n",
            "error: 0.263169, prediction: 0.28700000000000003\n",
            "error: 0.26265625, prediction: 0.28750000000000003\n",
            "error: 0.262144, prediction: 0.28800000000000003\n",
            "error: 0.26163225000000007, prediction: 0.28850000000000003\n",
            "error: 0.261121, prediction: 0.28900000000000003\n",
            "error: 0.26061024999999993, prediction: 0.28950000000000004\n",
            "error: 0.2601, prediction: 0.29000000000000004\n",
            "error: 0.2595902500000001, prediction: 0.29050000000000004\n",
            "error: 0.259081, prediction: 0.29100000000000004\n",
            "error: 0.25857224999999995, prediction: 0.29150000000000004\n",
            "error: 0.258064, prediction: 0.29200000000000004\n",
            "error: 0.25755625000000004, prediction: 0.29250000000000004\n",
            "error: 0.257049, prediction: 0.29300000000000004\n",
            "error: 0.25654224999999997, prediction: 0.29350000000000004\n",
            "error: 0.256036, prediction: 0.29400000000000004\n",
            "error: 0.25553025000000007, prediction: 0.29450000000000004\n",
            "error: 0.255025, prediction: 0.29500000000000004\n",
            "error: 0.25452024999999995, prediction: 0.29550000000000004\n",
            "error: 0.254016, prediction: 0.29600000000000004\n",
            "error: 0.25351225000000005, prediction: 0.29650000000000004\n",
            "error: 0.253009, prediction: 0.29700000000000004\n",
            "error: 0.25250624999999993, prediction: 0.29750000000000004\n",
            "error: 0.252004, prediction: 0.29800000000000004\n",
            "error: 0.25150225000000004, prediction: 0.29850000000000004\n",
            "error: 0.251001, prediction: 0.29900000000000004\n",
            "error: 0.2505002499999999, prediction: 0.29950000000000004\n",
            "error: 0.25, prediction: 0.30000000000000004\n",
            "error: 0.24950025, prediction: 0.30050000000000004\n",
            "error: 0.249001, prediction: 0.30100000000000005\n",
            "error: 0.24850225, prediction: 0.30150000000000005\n",
            "error: 0.248004, prediction: 0.30200000000000005\n",
            "error: 0.24750625, prediction: 0.30250000000000005\n",
            "error: 0.247009, prediction: 0.30300000000000005\n",
            "error: 0.24651225, prediction: 0.30350000000000005\n",
            "error: 0.24601599999999998, prediction: 0.30400000000000005\n",
            "error: 0.24552025, prediction: 0.30450000000000005\n",
            "error: 0.245025, prediction: 0.30500000000000005\n",
            "error: 0.24453025, prediction: 0.30550000000000005\n",
            "error: 0.244036, prediction: 0.30600000000000005\n",
            "error: 0.24354225, prediction: 0.30650000000000005\n",
            "error: 0.243049, prediction: 0.30700000000000005\n",
            "error: 0.24255625, prediction: 0.30750000000000005\n",
            "error: 0.242064, prediction: 0.30800000000000005\n",
            "error: 0.24157225, prediction: 0.30850000000000005\n",
            "error: 0.241081, prediction: 0.30900000000000005\n",
            "error: 0.24059025, prediction: 0.30950000000000005\n",
            "error: 0.24009999999999998, prediction: 0.31000000000000005\n",
            "error: 0.23961025, prediction: 0.31050000000000005\n",
            "error: 0.239121, prediction: 0.31100000000000005\n",
            "error: 0.23863225, prediction: 0.31150000000000005\n",
            "error: 0.238144, prediction: 0.31200000000000006\n",
            "error: 0.23765624999999999, prediction: 0.31250000000000006\n",
            "error: 0.237169, prediction: 0.31300000000000006\n",
            "error: 0.23668224999999998, prediction: 0.31350000000000006\n",
            "error: 0.236196, prediction: 0.31400000000000006\n",
            "error: 0.23571024999999998, prediction: 0.31450000000000006\n",
            "error: 0.235225, prediction: 0.31500000000000006\n",
            "error: 0.23474024999999998, prediction: 0.31550000000000006\n",
            "error: 0.234256, prediction: 0.31600000000000006\n",
            "error: 0.23377225, prediction: 0.31650000000000006\n",
            "error: 0.233289, prediction: 0.31700000000000006\n",
            "error: 0.23280625, prediction: 0.31750000000000006\n",
            "error: 0.23232399999999997, prediction: 0.31800000000000006\n",
            "error: 0.23184224999999997, prediction: 0.31850000000000006\n",
            "error: 0.23136099999999998, prediction: 0.31900000000000006\n",
            "error: 0.23088024999999998, prediction: 0.31950000000000006\n",
            "error: 0.2304, prediction: 0.32000000000000006\n",
            "error: 0.22992025, prediction: 0.32050000000000006\n",
            "error: 0.22944099999999998, prediction: 0.32100000000000006\n",
            "error: 0.22896224999999998, prediction: 0.32150000000000006\n",
            "error: 0.228484, prediction: 0.32200000000000006\n",
            "error: 0.22800625, prediction: 0.32250000000000006\n",
            "error: 0.22752899999999998, prediction: 0.32300000000000006\n",
            "error: 0.22705224999999998, prediction: 0.32350000000000007\n",
            "error: 0.22657599999999997, prediction: 0.32400000000000007\n",
            "error: 0.22610024999999997, prediction: 0.32450000000000007\n",
            "error: 0.225625, prediction: 0.32500000000000007\n",
            "error: 0.22515024999999997, prediction: 0.32550000000000007\n",
            "error: 0.224676, prediction: 0.32600000000000007\n",
            "error: 0.22420224999999996, prediction: 0.32650000000000007\n",
            "error: 0.22372899999999998, prediction: 0.32700000000000007\n",
            "error: 0.22325625, prediction: 0.32750000000000007\n",
            "error: 0.22278399999999998, prediction: 0.32800000000000007\n",
            "error: 0.22231225, prediction: 0.32850000000000007\n",
            "error: 0.22184099999999998, prediction: 0.32900000000000007\n",
            "error: 0.22137024999999996, prediction: 0.32950000000000007\n",
            "error: 0.22089999999999999, prediction: 0.33000000000000007\n",
            "error: 0.22043024999999997, prediction: 0.33050000000000007\n",
            "error: 0.21996099999999996, prediction: 0.33100000000000007\n",
            "error: 0.21949224999999997, prediction: 0.3315000000000001\n",
            "error: 0.21902399999999997, prediction: 0.3320000000000001\n",
            "error: 0.21855624999999998, prediction: 0.3325000000000001\n",
            "error: 0.21808899999999998, prediction: 0.3330000000000001\n",
            "error: 0.21762224999999996, prediction: 0.3335000000000001\n",
            "error: 0.21715599999999996, prediction: 0.3340000000000001\n",
            "error: 0.21669024999999997, prediction: 0.3345000000000001\n",
            "error: 0.21622499999999997, prediction: 0.3350000000000001\n",
            "error: 0.21576024999999996, prediction: 0.3355000000000001\n",
            "error: 0.21529599999999996, prediction: 0.3360000000000001\n",
            "error: 0.21483224999999997, prediction: 0.3365000000000001\n",
            "error: 0.21436899999999998, prediction: 0.3370000000000001\n",
            "error: 0.21390624999999996, prediction: 0.3375000000000001\n",
            "error: 0.21344399999999997, prediction: 0.3380000000000001\n",
            "error: 0.21298224999999996, prediction: 0.3385000000000001\n",
            "error: 0.21252099999999996, prediction: 0.3390000000000001\n",
            "error: 0.21206024999999998, prediction: 0.3395000000000001\n",
            "error: 0.21159999999999995, prediction: 0.3400000000000001\n",
            "error: 0.21114024999999997, prediction: 0.3405000000000001\n",
            "error: 0.21068099999999998, prediction: 0.3410000000000001\n",
            "error: 0.21022224999999997, prediction: 0.3415000000000001\n",
            "error: 0.20976399999999998, prediction: 0.3420000000000001\n",
            "error: 0.20930624999999997, prediction: 0.3425000000000001\n",
            "error: 0.20884899999999995, prediction: 0.3430000000000001\n",
            "error: 0.20839224999999997, prediction: 0.3435000000000001\n",
            "error: 0.20793599999999995, prediction: 0.3440000000000001\n",
            "error: 0.20748024999999998, prediction: 0.3445000000000001\n",
            "error: 0.20702499999999996, prediction: 0.3450000000000001\n",
            "error: 0.20657024999999996, prediction: 0.3455000000000001\n",
            "error: 0.20611599999999997, prediction: 0.3460000000000001\n",
            "error: 0.20566224999999996, prediction: 0.3465000000000001\n",
            "error: 0.20520899999999997, prediction: 0.3470000000000001\n",
            "error: 0.20475624999999997, prediction: 0.3475000000000001\n",
            "error: 0.20430399999999996, prediction: 0.3480000000000001\n",
            "error: 0.20385224999999996, prediction: 0.3485000000000001\n",
            "error: 0.20340099999999997, prediction: 0.3490000000000001\n",
            "error: 0.20295024999999997, prediction: 0.3495000000000001\n",
            "error: 0.20249999999999996, prediction: 0.3500000000000001\n",
            "error: 0.20205024999999996, prediction: 0.3505000000000001\n",
            "error: 0.20160099999999995, prediction: 0.3510000000000001\n",
            "error: 0.20115224999999995, prediction: 0.3515000000000001\n",
            "error: 0.20070399999999997, prediction: 0.3520000000000001\n",
            "error: 0.20025624999999997, prediction: 0.3525000000000001\n",
            "error: 0.19980899999999996, prediction: 0.3530000000000001\n",
            "error: 0.19936224999999996, prediction: 0.3535000000000001\n",
            "error: 0.19891599999999995, prediction: 0.3540000000000001\n",
            "error: 0.19847024999999996, prediction: 0.3545000000000001\n",
            "error: 0.19802499999999995, prediction: 0.3550000000000001\n",
            "error: 0.19758024999999996, prediction: 0.3555000000000001\n",
            "error: 0.19713599999999995, prediction: 0.3560000000000001\n",
            "error: 0.19669224999999996, prediction: 0.3565000000000001\n",
            "error: 0.19624899999999995, prediction: 0.3570000000000001\n",
            "error: 0.19580624999999996, prediction: 0.3575000000000001\n",
            "error: 0.19536399999999995, prediction: 0.3580000000000001\n",
            "error: 0.19492224999999996, prediction: 0.3585000000000001\n",
            "error: 0.19448099999999996, prediction: 0.3590000000000001\n",
            "error: 0.19404024999999994, prediction: 0.3595000000000001\n",
            "error: 0.19359999999999997, prediction: 0.3600000000000001\n",
            "error: 0.19316024999999995, prediction: 0.3605000000000001\n",
            "error: 0.19272099999999995, prediction: 0.3610000000000001\n",
            "error: 0.19228224999999996, prediction: 0.3615000000000001\n",
            "error: 0.19184399999999996, prediction: 0.3620000000000001\n",
            "error: 0.19140624999999994, prediction: 0.3625000000000001\n",
            "error: 0.19096899999999994, prediction: 0.3630000000000001\n",
            "error: 0.19053224999999996, prediction: 0.3635000000000001\n",
            "error: 0.19009599999999996, prediction: 0.3640000000000001\n",
            "error: 0.18966024999999995, prediction: 0.3645000000000001\n",
            "error: 0.18922499999999995, prediction: 0.3650000000000001\n",
            "error: 0.18879024999999994, prediction: 0.3655000000000001\n",
            "error: 0.18835599999999994, prediction: 0.3660000000000001\n",
            "error: 0.18792224999999996, prediction: 0.3665000000000001\n",
            "error: 0.18748899999999996, prediction: 0.3670000000000001\n",
            "error: 0.18705624999999995, prediction: 0.3675000000000001\n",
            "error: 0.18662399999999996, prediction: 0.3680000000000001\n",
            "error: 0.18619224999999995, prediction: 0.3685000000000001\n",
            "error: 0.18576099999999995, prediction: 0.3690000000000001\n",
            "error: 0.18533024999999995, prediction: 0.3695000000000001\n",
            "error: 0.18489999999999995, prediction: 0.3700000000000001\n",
            "error: 0.18447024999999995, prediction: 0.3705000000000001\n",
            "error: 0.18404099999999995, prediction: 0.3710000000000001\n",
            "error: 0.18361224999999995, prediction: 0.3715000000000001\n",
            "error: 0.18318399999999996, prediction: 0.3720000000000001\n",
            "error: 0.18275624999999995, prediction: 0.3725000000000001\n",
            "error: 0.18232899999999994, prediction: 0.3730000000000001\n",
            "error: 0.18190224999999993, prediction: 0.3735000000000001\n",
            "error: 0.18147599999999994, prediction: 0.3740000000000001\n",
            "error: 0.18105024999999994, prediction: 0.3745000000000001\n",
            "error: 0.18062499999999995, prediction: 0.3750000000000001\n",
            "error: 0.18020024999999995, prediction: 0.3755000000000001\n",
            "error: 0.17977599999999994, prediction: 0.3760000000000001\n",
            "error: 0.17935224999999994, prediction: 0.3765000000000001\n",
            "error: 0.17892899999999995, prediction: 0.3770000000000001\n",
            "error: 0.17850624999999995, prediction: 0.3775000000000001\n",
            "error: 0.17808399999999994, prediction: 0.3780000000000001\n",
            "error: 0.17766224999999994, prediction: 0.3785000000000001\n",
            "error: 0.17724099999999995, prediction: 0.3790000000000001\n",
            "error: 0.17682024999999993, prediction: 0.3795000000000001\n",
            "error: 0.17639999999999995, prediction: 0.3800000000000001\n",
            "error: 0.17598024999999995, prediction: 0.3805000000000001\n",
            "error: 0.17556099999999994, prediction: 0.3810000000000001\n",
            "error: 0.17514224999999994, prediction: 0.3815000000000001\n",
            "error: 0.17472399999999993, prediction: 0.3820000000000001\n",
            "error: 0.17430624999999994, prediction: 0.3825000000000001\n",
            "error: 0.17388899999999993, prediction: 0.3830000000000001\n",
            "error: 0.17347224999999994, prediction: 0.3835000000000001\n",
            "error: 0.17305599999999993, prediction: 0.3840000000000001\n",
            "error: 0.17264024999999994, prediction: 0.3845000000000001\n",
            "error: 0.17222499999999993, prediction: 0.3850000000000001\n",
            "error: 0.17181024999999994, prediction: 0.3855000000000001\n",
            "error: 0.17139599999999994, prediction: 0.3860000000000001\n",
            "error: 0.17098224999999995, prediction: 0.3865000000000001\n",
            "error: 0.17056899999999994, prediction: 0.3870000000000001\n",
            "error: 0.17015624999999993, prediction: 0.3875000000000001\n",
            "error: 0.16974399999999992, prediction: 0.3880000000000001\n",
            "error: 0.16933224999999993, prediction: 0.3885000000000001\n",
            "error: 0.16892099999999993, prediction: 0.3890000000000001\n",
            "error: 0.16851024999999994, prediction: 0.3895000000000001\n",
            "error: 0.16809999999999994, prediction: 0.3900000000000001\n",
            "error: 0.16769024999999993, prediction: 0.3905000000000001\n",
            "error: 0.16728099999999993, prediction: 0.3910000000000001\n",
            "error: 0.16687224999999994, prediction: 0.3915000000000001\n",
            "error: 0.16646399999999995, prediction: 0.3920000000000001\n",
            "error: 0.16605624999999993, prediction: 0.3925000000000001\n",
            "error: 0.16564899999999994, prediction: 0.3930000000000001\n",
            "error: 0.16524224999999992, prediction: 0.3935000000000001\n",
            "error: 0.16483599999999993, prediction: 0.39400000000000013\n",
            "error: 0.16443024999999994, prediction: 0.39450000000000013\n",
            "error: 0.16402499999999992, prediction: 0.39500000000000013\n",
            "error: 0.16362024999999994, prediction: 0.39550000000000013\n",
            "error: 0.16321599999999994, prediction: 0.39600000000000013\n",
            "error: 0.16281224999999994, prediction: 0.39650000000000013\n",
            "error: 0.16240899999999994, prediction: 0.39700000000000013\n",
            "error: 0.16200624999999994, prediction: 0.39750000000000013\n",
            "error: 0.16160399999999994, prediction: 0.39800000000000013\n",
            "error: 0.16120224999999994, prediction: 0.39850000000000013\n",
            "error: 0.16080099999999992, prediction: 0.39900000000000013\n",
            "error: 0.16040024999999994, prediction: 0.39950000000000013\n",
            "error: 0.15999999999999992, prediction: 0.40000000000000013\n",
            "error: 0.15960024999999992, prediction: 0.40050000000000013\n",
            "error: 0.15920099999999993, prediction: 0.40100000000000013\n",
            "error: 0.15880224999999992, prediction: 0.40150000000000013\n",
            "error: 0.15840399999999993, prediction: 0.40200000000000014\n",
            "error: 0.15800624999999993, prediction: 0.40250000000000014\n",
            "error: 0.15760899999999992, prediction: 0.40300000000000014\n",
            "error: 0.15721224999999991, prediction: 0.40350000000000014\n",
            "error: 0.15681599999999993, prediction: 0.40400000000000014\n",
            "error: 0.15642024999999993, prediction: 0.40450000000000014\n",
            "error: 0.1560249999999999, prediction: 0.40500000000000014\n",
            "error: 0.15563024999999991, prediction: 0.40550000000000014\n",
            "error: 0.15523599999999993, prediction: 0.40600000000000014\n",
            "error: 0.15484224999999993, prediction: 0.40650000000000014\n",
            "error: 0.15444899999999992, prediction: 0.40700000000000014\n",
            "error: 0.15405624999999992, prediction: 0.40750000000000014\n",
            "error: 0.1536639999999999, prediction: 0.40800000000000014\n",
            "error: 0.15327224999999992, prediction: 0.40850000000000014\n",
            "error: 0.15288099999999993, prediction: 0.40900000000000014\n",
            "error: 0.1524902499999999, prediction: 0.40950000000000014\n",
            "error: 0.15209999999999993, prediction: 0.41000000000000014\n",
            "error: 0.15171024999999994, prediction: 0.41050000000000014\n",
            "error: 0.15132099999999993, prediction: 0.41100000000000014\n",
            "error: 0.15093224999999993, prediction: 0.41150000000000014\n",
            "error: 0.15054399999999993, prediction: 0.41200000000000014\n",
            "error: 0.15015624999999994, prediction: 0.41250000000000014\n",
            "error: 0.14976899999999993, prediction: 0.41300000000000014\n",
            "error: 0.1493822499999999, prediction: 0.41350000000000015\n",
            "error: 0.14899599999999993, prediction: 0.41400000000000015\n",
            "error: 0.14861024999999992, prediction: 0.41450000000000015\n",
            "error: 0.1482249999999999, prediction: 0.41500000000000015\n",
            "error: 0.14784024999999992, prediction: 0.41550000000000015\n",
            "error: 0.14745599999999992, prediction: 0.41600000000000015\n",
            "error: 0.14707224999999993, prediction: 0.41650000000000015\n",
            "error: 0.14668899999999993, prediction: 0.41700000000000015\n",
            "error: 0.14630624999999992, prediction: 0.41750000000000015\n",
            "error: 0.14592399999999991, prediction: 0.41800000000000015\n",
            "error: 0.14554224999999993, prediction: 0.41850000000000015\n",
            "error: 0.14516099999999993, prediction: 0.41900000000000015\n",
            "error: 0.14478024999999992, prediction: 0.41950000000000015\n",
            "error: 0.14439999999999992, prediction: 0.42000000000000015\n",
            "error: 0.1440202499999999, prediction: 0.42050000000000015\n",
            "error: 0.1436409999999999, prediction: 0.42100000000000015\n",
            "error: 0.14326224999999992, prediction: 0.42150000000000015\n",
            "error: 0.14288399999999993, prediction: 0.42200000000000015\n",
            "error: 0.14250624999999992, prediction: 0.42250000000000015\n",
            "error: 0.14212899999999992, prediction: 0.42300000000000015\n",
            "error: 0.1417522499999999, prediction: 0.42350000000000015\n",
            "error: 0.14137599999999992, prediction: 0.42400000000000015\n",
            "error: 0.1410002499999999, prediction: 0.42450000000000015\n",
            "error: 0.14062499999999992, prediction: 0.42500000000000016\n",
            "error: 0.1402502499999999, prediction: 0.42550000000000016\n",
            "error: 0.13987599999999992, prediction: 0.42600000000000016\n",
            "error: 0.1395022499999999, prediction: 0.42650000000000016\n",
            "error: 0.13912899999999992, prediction: 0.42700000000000016\n",
            "error: 0.13875624999999991, prediction: 0.42750000000000016\n",
            "error: 0.13838399999999992, prediction: 0.42800000000000016\n",
            "error: 0.13801224999999992, prediction: 0.42850000000000016\n",
            "error: 0.1376409999999999, prediction: 0.42900000000000016\n",
            "error: 0.13727024999999993, prediction: 0.42950000000000016\n",
            "error: 0.1368999999999999, prediction: 0.43000000000000016\n",
            "error: 0.1365302499999999, prediction: 0.43050000000000016\n",
            "error: 0.13616099999999992, prediction: 0.43100000000000016\n",
            "error: 0.13579224999999992, prediction: 0.43150000000000016\n",
            "error: 0.1354239999999999, prediction: 0.43200000000000016\n",
            "error: 0.1350562499999999, prediction: 0.43250000000000016\n",
            "error: 0.13468899999999992, prediction: 0.43300000000000016\n",
            "error: 0.13432224999999992, prediction: 0.43350000000000016\n",
            "error: 0.1339559999999999, prediction: 0.43400000000000016\n",
            "error: 0.1335902499999999, prediction: 0.43450000000000016\n",
            "error: 0.1332249999999999, prediction: 0.43500000000000016\n",
            "error: 0.1328602499999999, prediction: 0.43550000000000016\n",
            "error: 0.13249599999999992, prediction: 0.43600000000000017\n",
            "error: 0.13213224999999992, prediction: 0.43650000000000017\n",
            "error: 0.13176899999999991, prediction: 0.43700000000000017\n",
            "error: 0.13140624999999992, prediction: 0.43750000000000017\n",
            "error: 0.1310439999999999, prediction: 0.43800000000000017\n",
            "error: 0.13068224999999992, prediction: 0.43850000000000017\n",
            "error: 0.1303209999999999, prediction: 0.43900000000000017\n",
            "error: 0.12996024999999992, prediction: 0.43950000000000017\n",
            "error: 0.1295999999999999, prediction: 0.44000000000000017\n",
            "error: 0.12924024999999992, prediction: 0.44050000000000017\n",
            "error: 0.1288809999999999, prediction: 0.44100000000000017\n",
            "error: 0.12852224999999992, prediction: 0.44150000000000017\n",
            "error: 0.12816399999999992, prediction: 0.44200000000000017\n",
            "error: 0.1278062499999999, prediction: 0.44250000000000017\n",
            "error: 0.1274489999999999, prediction: 0.44300000000000017\n",
            "error: 0.1270922499999999, prediction: 0.44350000000000017\n",
            "error: 0.1267359999999999, prediction: 0.4440000000000002\n",
            "error: 0.12638024999999992, prediction: 0.4445000000000002\n",
            "error: 0.12602499999999991, prediction: 0.4450000000000002\n",
            "error: 0.1256702499999999, prediction: 0.4455000000000002\n",
            "error: 0.1253159999999999, prediction: 0.4460000000000002\n",
            "error: 0.12496224999999991, prediction: 0.4465000000000002\n",
            "error: 0.12460899999999991, prediction: 0.4470000000000002\n",
            "error: 0.1242562499999999, prediction: 0.4475000000000002\n",
            "error: 0.1239039999999999, prediction: 0.4480000000000002\n",
            "error: 0.1235522499999999, prediction: 0.4485000000000002\n",
            "error: 0.12320099999999991, prediction: 0.4490000000000002\n",
            "error: 0.12285024999999991, prediction: 0.4495000000000002\n",
            "error: 0.1224999999999999, prediction: 0.4500000000000002\n",
            "error: 0.1221502499999999, prediction: 0.4505000000000002\n",
            "error: 0.12180099999999991, prediction: 0.4510000000000002\n",
            "error: 0.1214522499999999, prediction: 0.4515000000000002\n",
            "error: 0.1211039999999999, prediction: 0.4520000000000002\n",
            "error: 0.12075624999999991, prediction: 0.4525000000000002\n",
            "error: 0.1204089999999999, prediction: 0.4530000000000002\n",
            "error: 0.12006224999999991, prediction: 0.4535000000000002\n",
            "error: 0.1197159999999999, prediction: 0.4540000000000002\n",
            "error: 0.1193702499999999, prediction: 0.4545000000000002\n",
            "error: 0.11902499999999991, prediction: 0.4550000000000002\n",
            "error: 0.1186802499999999, prediction: 0.4555000000000002\n",
            "error: 0.1183359999999999, prediction: 0.4560000000000002\n",
            "error: 0.11799224999999991, prediction: 0.4565000000000002\n",
            "error: 0.1176489999999999, prediction: 0.4570000000000002\n",
            "error: 0.1173062499999999, prediction: 0.4575000000000002\n",
            "error: 0.1169639999999999, prediction: 0.4580000000000002\n",
            "error: 0.1166222499999999, prediction: 0.4585000000000002\n",
            "error: 0.1162809999999999, prediction: 0.4590000000000002\n",
            "error: 0.1159402499999999, prediction: 0.4595000000000002\n",
            "error: 0.1155999999999999, prediction: 0.4600000000000002\n",
            "error: 0.1152602499999999, prediction: 0.4605000000000002\n",
            "error: 0.1149209999999999, prediction: 0.4610000000000002\n",
            "error: 0.1145822499999999, prediction: 0.4615000000000002\n",
            "error: 0.1142439999999999, prediction: 0.4620000000000002\n",
            "error: 0.1139062499999999, prediction: 0.4625000000000002\n",
            "error: 0.1135689999999999, prediction: 0.4630000000000002\n",
            "error: 0.1132322499999999, prediction: 0.4635000000000002\n",
            "error: 0.1128959999999999, prediction: 0.4640000000000002\n",
            "error: 0.1125602499999999, prediction: 0.4645000000000002\n",
            "error: 0.11222499999999991, prediction: 0.4650000000000002\n",
            "error: 0.1118902499999999, prediction: 0.4655000000000002\n",
            "error: 0.1115559999999999, prediction: 0.4660000000000002\n",
            "error: 0.1112222499999999, prediction: 0.4665000000000002\n",
            "error: 0.1108889999999999, prediction: 0.4670000000000002\n",
            "error: 0.1105562499999999, prediction: 0.4675000000000002\n",
            "error: 0.1102239999999999, prediction: 0.4680000000000002\n",
            "error: 0.1098922499999999, prediction: 0.4685000000000002\n",
            "error: 0.1095609999999999, prediction: 0.4690000000000002\n",
            "error: 0.1092302499999999, prediction: 0.4695000000000002\n",
            "error: 0.1088999999999999, prediction: 0.4700000000000002\n",
            "error: 0.1085702499999999, prediction: 0.4705000000000002\n",
            "error: 0.1082409999999999, prediction: 0.4710000000000002\n",
            "error: 0.1079122499999999, prediction: 0.4715000000000002\n",
            "error: 0.1075839999999999, prediction: 0.4720000000000002\n",
            "error: 0.1072562499999999, prediction: 0.4725000000000002\n",
            "error: 0.1069289999999999, prediction: 0.4730000000000002\n",
            "error: 0.1066022499999999, prediction: 0.4735000000000002\n",
            "error: 0.1062759999999999, prediction: 0.4740000000000002\n",
            "error: 0.1059502499999999, prediction: 0.4745000000000002\n",
            "error: 0.1056249999999999, prediction: 0.4750000000000002\n",
            "error: 0.1053002499999999, prediction: 0.4755000000000002\n",
            "error: 0.1049759999999999, prediction: 0.4760000000000002\n",
            "error: 0.1046522499999999, prediction: 0.4765000000000002\n",
            "error: 0.1043289999999999, prediction: 0.4770000000000002\n",
            "error: 0.1040062499999999, prediction: 0.4775000000000002\n",
            "error: 0.1036839999999999, prediction: 0.4780000000000002\n",
            "error: 0.10336224999999989, prediction: 0.4785000000000002\n",
            "error: 0.1030409999999999, prediction: 0.4790000000000002\n",
            "error: 0.1027202499999999, prediction: 0.4795000000000002\n",
            "error: 0.1023999999999999, prediction: 0.4800000000000002\n",
            "error: 0.1020802499999999, prediction: 0.4805000000000002\n",
            "error: 0.1017609999999999, prediction: 0.4810000000000002\n",
            "error: 0.1014422499999999, prediction: 0.4815000000000002\n",
            "error: 0.1011239999999999, prediction: 0.4820000000000002\n",
            "error: 0.1008062499999999, prediction: 0.4825000000000002\n",
            "error: 0.1004889999999999, prediction: 0.4830000000000002\n",
            "error: 0.1001722499999999, prediction: 0.4835000000000002\n",
            "error: 0.0998559999999999, prediction: 0.4840000000000002\n",
            "error: 0.0995402499999999, prediction: 0.4845000000000002\n",
            "error: 0.0992249999999999, prediction: 0.4850000000000002\n",
            "error: 0.0989102499999999, prediction: 0.4855000000000002\n",
            "error: 0.09859599999999989, prediction: 0.4860000000000002\n",
            "error: 0.09828224999999989, prediction: 0.4865000000000002\n",
            "error: 0.09796899999999989, prediction: 0.4870000000000002\n",
            "error: 0.0976562499999999, prediction: 0.4875000000000002\n",
            "error: 0.09734399999999989, prediction: 0.4880000000000002\n",
            "error: 0.09703224999999989, prediction: 0.4885000000000002\n",
            "error: 0.09672099999999989, prediction: 0.4890000000000002\n",
            "error: 0.09641024999999989, prediction: 0.4895000000000002\n",
            "error: 0.0960999999999999, prediction: 0.4900000000000002\n",
            "error: 0.0957902499999999, prediction: 0.4905000000000002\n",
            "error: 0.0954809999999999, prediction: 0.4910000000000002\n",
            "error: 0.09517224999999989, prediction: 0.4915000000000002\n",
            "error: 0.09486399999999989, prediction: 0.4920000000000002\n",
            "error: 0.0945562499999999, prediction: 0.4925000000000002\n",
            "error: 0.09424899999999989, prediction: 0.4930000000000002\n",
            "error: 0.0939422499999999, prediction: 0.4935000000000002\n",
            "error: 0.0936359999999999, prediction: 0.4940000000000002\n",
            "error: 0.09333024999999989, prediction: 0.4945000000000002\n",
            "error: 0.0930249999999999, prediction: 0.4950000000000002\n",
            "error: 0.09272024999999989, prediction: 0.4955000000000002\n",
            "error: 0.0924159999999999, prediction: 0.4960000000000002\n",
            "error: 0.0921122499999999, prediction: 0.4965000000000002\n",
            "error: 0.09180899999999989, prediction: 0.4970000000000002\n",
            "error: 0.0915062499999999, prediction: 0.4975000000000002\n",
            "error: 0.0912039999999999, prediction: 0.4980000000000002\n",
            "error: 0.09090224999999989, prediction: 0.4985000000000002\n",
            "error: 0.09060099999999989, prediction: 0.4990000000000002\n",
            "error: 0.09030024999999989, prediction: 0.4995000000000002\n",
            "error: 0.0899999999999999, prediction: 0.5000000000000002\n",
            "error: 0.08970024999999993, prediction: 0.5005000000000002\n",
            "error: 0.08940099999999995, prediction: 0.5010000000000001\n",
            "error: 0.08910225, prediction: 0.5015000000000001\n",
            "error: 0.08880400000000002, prediction: 0.502\n",
            "error: 0.08850625000000006, prediction: 0.5025\n",
            "error: 0.08820900000000009, prediction: 0.5029999999999999\n",
            "error: 0.08791225000000012, prediction: 0.5034999999999998\n",
            "error: 0.08761600000000015, prediction: 0.5039999999999998\n",
            "error: 0.08732025000000018, prediction: 0.5044999999999997\n",
            "error: 0.08702500000000021, prediction: 0.5049999999999997\n",
            "error: 0.08673025000000026, prediction: 0.5054999999999996\n",
            "error: 0.08643600000000029, prediction: 0.5059999999999996\n",
            "error: 0.08614225000000032, prediction: 0.5064999999999995\n",
            "error: 0.08584900000000034, prediction: 0.5069999999999995\n",
            "error: 0.08555625000000038, prediction: 0.5074999999999994\n",
            "error: 0.08526400000000041, prediction: 0.5079999999999993\n",
            "error: 0.08497225000000044, prediction: 0.5084999999999993\n",
            "error: 0.08468100000000048, prediction: 0.5089999999999992\n",
            "error: 0.0843902500000005, prediction: 0.5094999999999992\n",
            "error: 0.08410000000000054, prediction: 0.5099999999999991\n",
            "error: 0.08381025000000057, prediction: 0.5104999999999991\n",
            "error: 0.0835210000000006, prediction: 0.510999999999999\n",
            "error: 0.08323225000000063, prediction: 0.511499999999999\n",
            "error: 0.08294400000000066, prediction: 0.5119999999999989\n",
            "error: 0.0826562500000007, prediction: 0.5124999999999988\n",
            "error: 0.08236900000000072, prediction: 0.5129999999999988\n",
            "error: 0.08208225000000074, prediction: 0.5134999999999987\n",
            "error: 0.08179600000000078, prediction: 0.5139999999999987\n",
            "error: 0.08151025000000081, prediction: 0.5144999999999986\n",
            "error: 0.08122500000000084, prediction: 0.5149999999999986\n",
            "error: 0.08094025000000087, prediction: 0.5154999999999985\n",
            "error: 0.0806560000000009, prediction: 0.5159999999999985\n",
            "error: 0.08037225000000094, prediction: 0.5164999999999984\n",
            "error: 0.08008900000000096, prediction: 0.5169999999999983\n",
            "error: 0.079806250000001, prediction: 0.5174999999999983\n",
            "error: 0.07952400000000102, prediction: 0.5179999999999982\n",
            "error: 0.07924225000000104, prediction: 0.5184999999999982\n",
            "error: 0.07896100000000107, prediction: 0.5189999999999981\n",
            "error: 0.0786802500000011, prediction: 0.5194999999999981\n",
            "error: 0.07840000000000114, prediction: 0.519999999999998\n",
            "error: 0.07812025000000117, prediction: 0.520499999999998\n",
            "error: 0.07784100000000119, prediction: 0.5209999999999979\n",
            "error: 0.07756225000000122, prediction: 0.5214999999999979\n",
            "error: 0.07728400000000125, prediction: 0.5219999999999978\n",
            "error: 0.07700625000000128, prediction: 0.5224999999999977\n",
            "error: 0.07672900000000131, prediction: 0.5229999999999977\n",
            "error: 0.07645225000000133, prediction: 0.5234999999999976\n",
            "error: 0.07617600000000137, prediction: 0.5239999999999976\n",
            "error: 0.07590025000000139, prediction: 0.5244999999999975\n",
            "error: 0.07562500000000141, prediction: 0.5249999999999975\n",
            "error: 0.07535025000000145, prediction: 0.5254999999999974\n",
            "error: 0.07507600000000147, prediction: 0.5259999999999974\n",
            "error: 0.0748022500000015, prediction: 0.5264999999999973\n",
            "error: 0.07452900000000152, prediction: 0.5269999999999972\n",
            "error: 0.07425625000000155, prediction: 0.5274999999999972\n",
            "error: 0.07398400000000158, prediction: 0.5279999999999971\n",
            "error: 0.0737122500000016, prediction: 0.5284999999999971\n",
            "error: 0.07344100000000163, prediction: 0.528999999999997\n",
            "error: 0.07317025000000166, prediction: 0.529499999999997\n",
            "error: 0.07290000000000169, prediction: 0.5299999999999969\n",
            "error: 0.07263025000000171, prediction: 0.5304999999999969\n",
            "error: 0.07236100000000174, prediction: 0.5309999999999968\n",
            "error: 0.07209225000000177, prediction: 0.5314999999999968\n",
            "error: 0.07182400000000179, prediction: 0.5319999999999967\n",
            "error: 0.07155625000000182, prediction: 0.5324999999999966\n",
            "error: 0.07128900000000185, prediction: 0.5329999999999966\n",
            "error: 0.07102225000000187, prediction: 0.5334999999999965\n",
            "error: 0.0707560000000019, prediction: 0.5339999999999965\n",
            "error: 0.07049025000000192, prediction: 0.5344999999999964\n",
            "error: 0.07022500000000195, prediction: 0.5349999999999964\n",
            "error: 0.06996025000000197, prediction: 0.5354999999999963\n",
            "error: 0.069696000000002, prediction: 0.5359999999999963\n",
            "error: 0.06943225000000203, prediction: 0.5364999999999962\n",
            "error: 0.06916900000000205, prediction: 0.5369999999999961\n",
            "error: 0.06890625000000207, prediction: 0.5374999999999961\n",
            "error: 0.0686440000000021, prediction: 0.537999999999996\n",
            "error: 0.06838225000000213, prediction: 0.538499999999996\n",
            "error: 0.06812100000000215, prediction: 0.5389999999999959\n",
            "error: 0.06786025000000218, prediction: 0.5394999999999959\n",
            "error: 0.0676000000000022, prediction: 0.5399999999999958\n",
            "error: 0.06734025000000222, prediction: 0.5404999999999958\n",
            "error: 0.06708100000000225, prediction: 0.5409999999999957\n",
            "error: 0.06682225000000228, prediction: 0.5414999999999957\n",
            "error: 0.0665640000000023, prediction: 0.5419999999999956\n",
            "error: 0.06630625000000231, prediction: 0.5424999999999955\n",
            "error: 0.06604900000000234, prediction: 0.5429999999999955\n",
            "error: 0.06579225000000237, prediction: 0.5434999999999954\n",
            "error: 0.06553600000000238, prediction: 0.5439999999999954\n",
            "error: 0.06528025000000241, prediction: 0.5444999999999953\n",
            "error: 0.06502500000000244, prediction: 0.5449999999999953\n",
            "error: 0.06477025000000246, prediction: 0.5454999999999952\n",
            "error: 0.06451600000000249, prediction: 0.5459999999999952\n",
            "error: 0.0642622500000025, prediction: 0.5464999999999951\n",
            "error: 0.06400900000000254, prediction: 0.546999999999995\n",
            "error: 0.06375625000000255, prediction: 0.547499999999995\n",
            "error: 0.06350400000000257, prediction: 0.5479999999999949\n",
            "error: 0.06325225000000259, prediction: 0.5484999999999949\n",
            "error: 0.06300100000000262, prediction: 0.5489999999999948\n",
            "error: 0.06275025000000264, prediction: 0.5494999999999948\n",
            "error: 0.06250000000000266, prediction: 0.5499999999999947\n",
            "error: 0.062250250000002685, prediction: 0.5504999999999947\n",
            "error: 0.06200100000000271, prediction: 0.5509999999999946\n",
            "error: 0.06175225000000273, prediction: 0.5514999999999946\n",
            "error: 0.06150400000000275, prediction: 0.5519999999999945\n",
            "error: 0.061256250000002774, prediction: 0.5524999999999944\n",
            "error: 0.0610090000000028, prediction: 0.5529999999999944\n",
            "error: 0.060762250000002814, prediction: 0.5534999999999943\n",
            "error: 0.06051600000000284, prediction: 0.5539999999999943\n",
            "error: 0.06027025000000286, prediction: 0.5544999999999942\n",
            "error: 0.06002500000000288, prediction: 0.5549999999999942\n",
            "error: 0.0597802500000029, prediction: 0.5554999999999941\n",
            "error: 0.05953600000000292, prediction: 0.555999999999994\n",
            "error: 0.05929225000000295, prediction: 0.556499999999994\n",
            "error: 0.05904900000000297, prediction: 0.5569999999999939\n",
            "error: 0.05880625000000299, prediction: 0.5574999999999939\n",
            "error: 0.058564000000003, prediction: 0.5579999999999938\n",
            "error: 0.058322250000003024, prediction: 0.5584999999999938\n",
            "error: 0.05808100000000305, prediction: 0.5589999999999937\n",
            "error: 0.05784025000000307, prediction: 0.5594999999999937\n",
            "error: 0.057600000000003086, prediction: 0.5599999999999936\n",
            "error: 0.0573602500000031, prediction: 0.5604999999999936\n",
            "error: 0.05712100000000313, prediction: 0.5609999999999935\n",
            "error: 0.056882250000003146, prediction: 0.5614999999999934\n",
            "error: 0.056644000000003164, prediction: 0.5619999999999934\n",
            "error: 0.05640625000000318, prediction: 0.5624999999999933\n",
            "error: 0.0561690000000032, prediction: 0.5629999999999933\n",
            "error: 0.05593225000000322, prediction: 0.5634999999999932\n",
            "error: 0.05569600000000324, prediction: 0.5639999999999932\n",
            "error: 0.055460250000003264, prediction: 0.5644999999999931\n",
            "error: 0.05522500000000328, prediction: 0.5649999999999931\n",
            "error: 0.0549902500000033, prediction: 0.565499999999993\n",
            "error: 0.054756000000003316, prediction: 0.565999999999993\n",
            "error: 0.05452225000000334, prediction: 0.5664999999999929\n",
            "error: 0.054289000000003355, prediction: 0.5669999999999928\n",
            "error: 0.05405625000000337, prediction: 0.5674999999999928\n",
            "error: 0.05382400000000339, prediction: 0.5679999999999927\n",
            "error: 0.05359225000000341, prediction: 0.5684999999999927\n",
            "error: 0.053361000000003427, prediction: 0.5689999999999926\n",
            "error: 0.053130250000003446, prediction: 0.5694999999999926\n",
            "error: 0.052900000000003465, prediction: 0.5699999999999925\n",
            "error: 0.052670250000003485, prediction: 0.5704999999999925\n",
            "error: 0.0524410000000035, prediction: 0.5709999999999924\n",
            "error: 0.05221225000000352, prediction: 0.5714999999999923\n",
            "error: 0.051984000000003534, prediction: 0.5719999999999923\n",
            "error: 0.05175625000000355, prediction: 0.5724999999999922\n",
            "error: 0.05152900000000357, prediction: 0.5729999999999922\n",
            "error: 0.05130225000000359, prediction: 0.5734999999999921\n",
            "error: 0.051076000000003605, prediction: 0.5739999999999921\n",
            "error: 0.05085025000000362, prediction: 0.574499999999992\n",
            "error: 0.05062500000000364, prediction: 0.574999999999992\n",
            "error: 0.05040025000000365, prediction: 0.5754999999999919\n",
            "error: 0.05017600000000367, prediction: 0.5759999999999919\n",
            "error: 0.04995225000000369, prediction: 0.5764999999999918\n",
            "error: 0.0497290000000037, prediction: 0.5769999999999917\n",
            "error: 0.04950625000000372, prediction: 0.5774999999999917\n",
            "error: 0.049284000000003735, prediction: 0.5779999999999916\n",
            "error: 0.04906225000000375, prediction: 0.5784999999999916\n",
            "error: 0.04884100000000377, prediction: 0.5789999999999915\n",
            "error: 0.048620250000003785, prediction: 0.5794999999999915\n",
            "error: 0.0484000000000038, prediction: 0.5799999999999914\n",
            "error: 0.04818025000000382, prediction: 0.5804999999999914\n",
            "error: 0.04796100000000383, prediction: 0.5809999999999913\n",
            "error: 0.047742250000003844, prediction: 0.5814999999999912\n",
            "error: 0.04752400000000386, prediction: 0.5819999999999912\n",
            "error: 0.04730625000000387, prediction: 0.5824999999999911\n",
            "error: 0.04708900000000389, prediction: 0.5829999999999911\n",
            "error: 0.046872250000003904, prediction: 0.583499999999991\n",
            "error: 0.04665600000000392, prediction: 0.583999999999991\n",
            "error: 0.04644025000000394, prediction: 0.5844999999999909\n",
            "error: 0.04622500000000395, prediction: 0.5849999999999909\n",
            "error: 0.046010250000003965, prediction: 0.5854999999999908\n",
            "error: 0.04579600000000398, prediction: 0.5859999999999908\n",
            "error: 0.045582250000003995, prediction: 0.5864999999999907\n",
            "error: 0.045369000000004, prediction: 0.5869999999999906\n",
            "error: 0.04515625000000402, prediction: 0.5874999999999906\n",
            "error: 0.044944000000004036, prediction: 0.5879999999999905\n",
            "error: 0.04473225000000405, prediction: 0.5884999999999905\n",
            "error: 0.044521000000004064, prediction: 0.5889999999999904\n",
            "error: 0.044310250000004076, prediction: 0.5894999999999904\n",
            "error: 0.04410000000000409, prediction: 0.5899999999999903\n",
            "error: 0.0438902500000041, prediction: 0.5904999999999903\n",
            "error: 0.04368100000000411, prediction: 0.5909999999999902\n",
            "error: 0.043472250000004126, prediction: 0.5914999999999901\n",
            "error: 0.04326400000000414, prediction: 0.5919999999999901\n",
            "error: 0.043056250000004154, prediction: 0.59249999999999\n",
            "error: 0.04284900000000417, prediction: 0.59299999999999\n",
            "error: 0.04264225000000418, prediction: 0.5934999999999899\n",
            "error: 0.04243600000000419, prediction: 0.5939999999999899\n",
            "error: 0.0422302500000042, prediction: 0.5944999999999898\n",
            "error: 0.04202500000000422, prediction: 0.5949999999999898\n",
            "error: 0.04182025000000423, prediction: 0.5954999999999897\n",
            "error: 0.04161600000000424, prediction: 0.5959999999999896\n",
            "error: 0.04141225000000425, prediction: 0.5964999999999896\n",
            "error: 0.04120900000000426, prediction: 0.5969999999999895\n",
            "error: 0.041006250000004275, prediction: 0.5974999999999895\n",
            "error: 0.04080400000000429, prediction: 0.5979999999999894\n",
            "error: 0.0406022500000043, prediction: 0.5984999999999894\n",
            "error: 0.04040100000000431, prediction: 0.5989999999999893\n",
            "error: 0.04020025000000432, prediction: 0.5994999999999893\n",
            "error: 0.04000000000000434, prediction: 0.5999999999999892\n",
            "error: 0.039800250000004346, prediction: 0.6004999999999892\n",
            "error: 0.039601000000004355, prediction: 0.6009999999999891\n",
            "error: 0.039402250000004364, prediction: 0.601499999999989\n",
            "error: 0.03920400000000438, prediction: 0.601999999999989\n",
            "error: 0.03900625000000439, prediction: 0.6024999999999889\n",
            "error: 0.0388090000000044, prediction: 0.6029999999999889\n",
            "error: 0.03861225000000441, prediction: 0.6034999999999888\n",
            "error: 0.03841600000000442, prediction: 0.6039999999999888\n",
            "error: 0.03822025000000443, prediction: 0.6044999999999887\n",
            "error: 0.038025000000004444, prediction: 0.6049999999999887\n",
            "error: 0.03783025000000445, prediction: 0.6054999999999886\n",
            "error: 0.03763600000000446, prediction: 0.6059999999999885\n",
            "error: 0.03744225000000447, prediction: 0.6064999999999885\n",
            "error: 0.03724900000000448, prediction: 0.6069999999999884\n",
            "error: 0.03705625000000449, prediction: 0.6074999999999884\n",
            "error: 0.0368640000000045, prediction: 0.6079999999999883\n",
            "error: 0.03667225000000451, prediction: 0.6084999999999883\n",
            "error: 0.03648100000000452, prediction: 0.6089999999999882\n",
            "error: 0.03629025000000453, prediction: 0.6094999999999882\n",
            "error: 0.03610000000000454, prediction: 0.6099999999999881\n",
            "error: 0.03591025000000454, prediction: 0.610499999999988\n",
            "error: 0.035721000000004555, prediction: 0.610999999999988\n",
            "error: 0.03553225000000456, prediction: 0.6114999999999879\n",
            "error: 0.03534400000000457, prediction: 0.6119999999999879\n",
            "error: 0.03515625000000458, prediction: 0.6124999999999878\n",
            "error: 0.03496900000000459, prediction: 0.6129999999999878\n",
            "error: 0.034782250000004594, prediction: 0.6134999999999877\n",
            "error: 0.0345960000000046, prediction: 0.6139999999999877\n",
            "error: 0.03441025000000461, prediction: 0.6144999999999876\n",
            "error: 0.03422500000000462, prediction: 0.6149999999999876\n",
            "error: 0.03404025000000463, prediction: 0.6154999999999875\n",
            "error: 0.03385600000000464, prediction: 0.6159999999999874\n",
            "error: 0.03367225000000464, prediction: 0.6164999999999874\n",
            "error: 0.033489000000004654, prediction: 0.6169999999999873\n",
            "error: 0.03330625000000466, prediction: 0.6174999999999873\n",
            "error: 0.033124000000004664, prediction: 0.6179999999999872\n",
            "error: 0.032942250000004676, prediction: 0.6184999999999872\n",
            "error: 0.03276100000000468, prediction: 0.6189999999999871\n",
            "error: 0.03258025000000469, prediction: 0.6194999999999871\n",
            "error: 0.032400000000004696, prediction: 0.619999999999987\n",
            "error: 0.0322202500000047, prediction: 0.620499999999987\n",
            "error: 0.032041000000004705, prediction: 0.6209999999999869\n",
            "error: 0.03186225000000471, prediction: 0.6214999999999868\n",
            "error: 0.03168400000000472, prediction: 0.6219999999999868\n",
            "error: 0.031506250000004725, prediction: 0.6224999999999867\n",
            "error: 0.031329000000004735, prediction: 0.6229999999999867\n",
            "error: 0.03115225000000474, prediction: 0.6234999999999866\n",
            "error: 0.030976000000004746, prediction: 0.6239999999999866\n",
            "error: 0.03080025000000475, prediction: 0.6244999999999865\n",
            "error: 0.030625000000004756, prediction: 0.6249999999999865\n",
            "error: 0.03045025000000476, prediction: 0.6254999999999864\n",
            "error: 0.030276000000004768, prediction: 0.6259999999999863\n",
            "error: 0.03010225000000477, prediction: 0.6264999999999863\n",
            "error: 0.029929000000004778, prediction: 0.6269999999999862\n",
            "error: 0.029756250000004782, prediction: 0.6274999999999862\n",
            "error: 0.029584000000004787, prediction: 0.6279999999999861\n",
            "error: 0.029412250000004792, prediction: 0.6284999999999861\n",
            "error: 0.029241000000004798, prediction: 0.628999999999986\n",
            "error: 0.029070250000004804, prediction: 0.629499999999986\n",
            "error: 0.028900000000004807, prediction: 0.6299999999999859\n",
            "error: 0.02873025000000481, prediction: 0.6304999999999858\n",
            "error: 0.028561000000004815, prediction: 0.6309999999999858\n",
            "error: 0.02839225000000482, prediction: 0.6314999999999857\n",
            "error: 0.028224000000004825, prediction: 0.6319999999999857\n",
            "error: 0.02805625000000483, prediction: 0.6324999999999856\n",
            "error: 0.027889000000004834, prediction: 0.6329999999999856\n",
            "error: 0.027722250000004837, prediction: 0.6334999999999855\n",
            "error: 0.02755600000000484, prediction: 0.6339999999999855\n",
            "error: 0.027390250000004845, prediction: 0.6344999999999854\n",
            "error: 0.02722500000000485, prediction: 0.6349999999999854\n",
            "error: 0.02706025000000485, prediction: 0.6354999999999853\n",
            "error: 0.026896000000004854, prediction: 0.6359999999999852\n",
            "error: 0.026732250000004856, prediction: 0.6364999999999852\n",
            "error: 0.02656900000000486, prediction: 0.6369999999999851\n",
            "error: 0.026406250000004863, prediction: 0.6374999999999851\n",
            "error: 0.026244000000004868, prediction: 0.637999999999985\n",
            "error: 0.02608225000000487, prediction: 0.638499999999985\n",
            "error: 0.02592100000000487, prediction: 0.6389999999999849\n",
            "error: 0.025760250000004873, prediction: 0.6394999999999849\n",
            "error: 0.025600000000004876, prediction: 0.6399999999999848\n",
            "error: 0.02544025000000488, prediction: 0.6404999999999847\n",
            "error: 0.025281000000004883, prediction: 0.6409999999999847\n",
            "error: 0.025122250000004884, prediction: 0.6414999999999846\n",
            "error: 0.024964000000004885, prediction: 0.6419999999999846\n",
            "error: 0.024806250000004887, prediction: 0.6424999999999845\n",
            "error: 0.02464900000000489, prediction: 0.6429999999999845\n",
            "error: 0.024492250000004892, prediction: 0.6434999999999844\n",
            "error: 0.024336000000004892, prediction: 0.6439999999999844\n",
            "error: 0.024180250000004896, prediction: 0.6444999999999843\n",
            "error: 0.024025000000004897, prediction: 0.6449999999999843\n",
            "error: 0.023870250000004898, prediction: 0.6454999999999842\n",
            "error: 0.023716000000004896, prediction: 0.6459999999999841\n",
            "error: 0.0235622500000049, prediction: 0.6464999999999841\n",
            "error: 0.023409000000004898, prediction: 0.646999999999984\n",
            "error: 0.0232562500000049, prediction: 0.647499999999984\n",
            "error: 0.023104000000004902, prediction: 0.6479999999999839\n",
            "error: 0.022952250000004903, prediction: 0.6484999999999839\n",
            "error: 0.0228010000000049, prediction: 0.6489999999999838\n",
            "error: 0.022650250000004903, prediction: 0.6494999999999838\n",
            "error: 0.0225000000000049, prediction: 0.6499999999999837\n",
            "error: 0.022350250000004904, prediction: 0.6504999999999836\n",
            "error: 0.022201000000004904, prediction: 0.6509999999999836\n",
            "error: 0.0220522500000049, prediction: 0.6514999999999835\n",
            "error: 0.021904000000004902, prediction: 0.6519999999999835\n",
            "error: 0.021756250000004904, prediction: 0.6524999999999834\n",
            "error: 0.021609000000004902, prediction: 0.6529999999999834\n",
            "error: 0.0214622500000049, prediction: 0.6534999999999833\n",
            "error: 0.0213160000000049, prediction: 0.6539999999999833\n",
            "error: 0.0211702500000049, prediction: 0.6544999999999832\n",
            "error: 0.021025000000004897, prediction: 0.6549999999999832\n",
            "error: 0.0208802500000049, prediction: 0.6554999999999831\n",
            "error: 0.020736000000004896, prediction: 0.655999999999983\n",
            "error: 0.020592250000004895, prediction: 0.656499999999983\n",
            "error: 0.020449000000004894, prediction: 0.6569999999999829\n",
            "error: 0.020306250000004893, prediction: 0.6574999999999829\n",
            "error: 0.02016400000000489, prediction: 0.6579999999999828\n",
            "error: 0.02002225000000489, prediction: 0.6584999999999828\n",
            "error: 0.019881000000004888, prediction: 0.6589999999999827\n",
            "error: 0.019740250000004886, prediction: 0.6594999999999827\n",
            "error: 0.019600000000004884, prediction: 0.6599999999999826\n",
            "error: 0.019460250000004883, prediction: 0.6604999999999825\n",
            "error: 0.01932100000000488, prediction: 0.6609999999999825\n",
            "error: 0.01918225000000488, prediction: 0.6614999999999824\n",
            "error: 0.019044000000004876, prediction: 0.6619999999999824\n",
            "error: 0.018906250000004874, prediction: 0.6624999999999823\n",
            "error: 0.01876900000000487, prediction: 0.6629999999999823\n",
            "error: 0.018632250000004867, prediction: 0.6634999999999822\n",
            "error: 0.018496000000004866, prediction: 0.6639999999999822\n",
            "error: 0.018360250000004862, prediction: 0.6644999999999821\n",
            "error: 0.01822500000000486, prediction: 0.664999999999982\n",
            "error: 0.018090250000004856, prediction: 0.665499999999982\n",
            "error: 0.017956000000004853, prediction: 0.6659999999999819\n",
            "error: 0.017822250000004848, prediction: 0.6664999999999819\n",
            "error: 0.017689000000004847, prediction: 0.6669999999999818\n",
            "error: 0.017556250000004842, prediction: 0.6674999999999818\n",
            "error: 0.01742400000000484, prediction: 0.6679999999999817\n",
            "error: 0.017292250000004835, prediction: 0.6684999999999817\n",
            "error: 0.01716100000000483, prediction: 0.6689999999999816\n",
            "error: 0.017030250000004826, prediction: 0.6694999999999816\n",
            "error: 0.01690000000000482, prediction: 0.6699999999999815\n",
            "error: 0.016770250000004816, prediction: 0.6704999999999814\n",
            "error: 0.01664100000000481, prediction: 0.6709999999999814\n",
            "error: 0.016512250000004808, prediction: 0.6714999999999813\n",
            "error: 0.016384000000004804, prediction: 0.6719999999999813\n",
            "error: 0.016256250000004798, prediction: 0.6724999999999812\n",
            "error: 0.016129000000004796, prediction: 0.6729999999999812\n",
            "error: 0.01600225000000479, prediction: 0.6734999999999811\n",
            "error: 0.015876000000004786, prediction: 0.6739999999999811\n",
            "error: 0.015750250000004778, prediction: 0.674499999999981\n",
            "error: 0.015625000000004774, prediction: 0.674999999999981\n",
            "error: 0.015500250000004769, prediction: 0.6754999999999809\n",
            "error: 0.015376000000004763, prediction: 0.6759999999999808\n",
            "error: 0.015252250000004757, prediction: 0.6764999999999808\n",
            "error: 0.015129000000004751, prediction: 0.6769999999999807\n",
            "error: 0.015006250000004747, prediction: 0.6774999999999807\n",
            "error: 0.01488400000000474, prediction: 0.6779999999999806\n",
            "error: 0.014762250000004733, prediction: 0.6784999999999806\n",
            "error: 0.014641000000004728, prediction: 0.6789999999999805\n",
            "error: 0.014520250000004722, prediction: 0.6794999999999805\n",
            "error: 0.014400000000004715, prediction: 0.6799999999999804\n",
            "error: 0.01428025000000471, prediction: 0.6804999999999803\n",
            "error: 0.014161000000004703, prediction: 0.6809999999999803\n",
            "error: 0.014042250000004695, prediction: 0.6814999999999802\n",
            "error: 0.013924000000004688, prediction: 0.6819999999999802\n",
            "error: 0.013806250000004681, prediction: 0.6824999999999801\n",
            "error: 0.013689000000004675, prediction: 0.6829999999999801\n",
            "error: 0.013572250000004667, prediction: 0.68349999999998\n",
            "error: 0.01345600000000466, prediction: 0.68399999999998\n",
            "error: 0.013340250000004652, prediction: 0.6844999999999799\n",
            "error: 0.013225000000004644, prediction: 0.6849999999999798\n",
            "error: 0.013110250000004637, prediction: 0.6854999999999798\n",
            "error: 0.01299600000000463, prediction: 0.6859999999999797\n",
            "error: 0.012882250000004623, prediction: 0.6864999999999797\n",
            "error: 0.012769000000004615, prediction: 0.6869999999999796\n",
            "error: 0.012656250000004607, prediction: 0.6874999999999796\n",
            "error: 0.012544000000004598, prediction: 0.6879999999999795\n",
            "error: 0.01243225000000459, prediction: 0.6884999999999795\n",
            "error: 0.012321000000004582, prediction: 0.6889999999999794\n",
            "error: 0.012210250000004573, prediction: 0.6894999999999794\n",
            "error: 0.012100000000004564, prediction: 0.6899999999999793\n",
            "error: 0.011990250000004556, prediction: 0.6904999999999792\n",
            "error: 0.011881000000004548, prediction: 0.6909999999999792\n",
            "error: 0.011772250000004538, prediction: 0.6914999999999791\n",
            "error: 0.011664000000004528, prediction: 0.6919999999999791\n",
            "error: 0.01155625000000452, prediction: 0.692499999999979\n",
            "error: 0.011449000000004511, prediction: 0.692999999999979\n",
            "error: 0.011342250000004502, prediction: 0.6934999999999789\n",
            "error: 0.011236000000004492, prediction: 0.6939999999999789\n",
            "error: 0.011130250000004482, prediction: 0.6944999999999788\n",
            "error: 0.011025000000004472, prediction: 0.6949999999999787\n",
            "error: 0.010920250000004463, prediction: 0.6954999999999787\n",
            "error: 0.010816000000004452, prediction: 0.6959999999999786\n",
            "error: 0.010712250000004442, prediction: 0.6964999999999786\n",
            "error: 0.010609000000004433, prediction: 0.6969999999999785\n",
            "error: 0.010506250000004422, prediction: 0.6974999999999785\n",
            "error: 0.010404000000004411, prediction: 0.6979999999999784\n",
            "error: 0.010302250000004402, prediction: 0.6984999999999784\n",
            "error: 0.01020100000000439, prediction: 0.6989999999999783\n",
            "error: 0.01010025000000438, prediction: 0.6994999999999783\n",
            "error: 0.01000000000000437, prediction: 0.6999999999999782\n",
            "error: 0.009900250000004359, prediction: 0.7004999999999781\n",
            "error: 0.009801000000004348, prediction: 0.7009999999999781\n",
            "error: 0.009702250000004338, prediction: 0.701499999999978\n",
            "error: 0.009604000000004326, prediction: 0.701999999999978\n",
            "error: 0.009506250000004315, prediction: 0.7024999999999779\n",
            "error: 0.009409000000004303, prediction: 0.7029999999999779\n",
            "error: 0.009312250000004291, prediction: 0.7034999999999778\n",
            "error: 0.00921600000000428, prediction: 0.7039999999999778\n",
            "error: 0.009120250000004267, prediction: 0.7044999999999777\n",
            "error: 0.009025000000004255, prediction: 0.7049999999999776\n",
            "error: 0.008930250000004244, prediction: 0.7054999999999776\n",
            "error: 0.008836000000004231, prediction: 0.7059999999999775\n",
            "error: 0.008742250000004219, prediction: 0.7064999999999775\n",
            "error: 0.008649000000004207, prediction: 0.7069999999999774\n",
            "error: 0.008556250000004194, prediction: 0.7074999999999774\n",
            "error: 0.008464000000004182, prediction: 0.7079999999999773\n",
            "error: 0.00837225000000417, prediction: 0.7084999999999773\n",
            "error: 0.008281000000004157, prediction: 0.7089999999999772\n",
            "error: 0.008190250000004144, prediction: 0.7094999999999771\n",
            "error: 0.008100000000004132, prediction: 0.7099999999999771\n",
            "error: 0.008010250000004118, prediction: 0.710499999999977\n",
            "error: 0.007921000000004105, prediction: 0.710999999999977\n",
            "error: 0.007832250000004091, prediction: 0.7114999999999769\n",
            "error: 0.007744000000004078, prediction: 0.7119999999999769\n",
            "error: 0.007656250000004064, prediction: 0.7124999999999768\n",
            "error: 0.007569000000004051, prediction: 0.7129999999999768\n",
            "error: 0.007482250000004037, prediction: 0.7134999999999767\n",
            "error: 0.0073960000000040235, prediction: 0.7139999999999767\n",
            "error: 0.00731025000000401, prediction: 0.7144999999999766\n",
            "error: 0.007225000000003996, prediction: 0.7149999999999765\n",
            "error: 0.007140250000003981, prediction: 0.7154999999999765\n",
            "error: 0.007056000000003967, prediction: 0.7159999999999764\n",
            "error: 0.006972250000003953, prediction: 0.7164999999999764\n",
            "error: 0.006889000000003938, prediction: 0.7169999999999763\n",
            "error: 0.006806250000003923, prediction: 0.7174999999999763\n",
            "error: 0.006724000000003908, prediction: 0.7179999999999762\n",
            "error: 0.006642250000003893, prediction: 0.7184999999999762\n",
            "error: 0.006561000000003879, prediction: 0.7189999999999761\n",
            "error: 0.006480250000003863, prediction: 0.719499999999976\n",
            "error: 0.006400000000003848, prediction: 0.719999999999976\n",
            "error: 0.006320250000003833, prediction: 0.7204999999999759\n",
            "error: 0.006241000000003817, prediction: 0.7209999999999759\n",
            "error: 0.006162250000003802, prediction: 0.7214999999999758\n",
            "error: 0.006084000000003786, prediction: 0.7219999999999758\n",
            "error: 0.006006250000003771, prediction: 0.7224999999999757\n",
            "error: 0.005929000000003755, prediction: 0.7229999999999757\n",
            "error: 0.005852250000003739, prediction: 0.7234999999999756\n",
            "error: 0.005776000000003723, prediction: 0.7239999999999756\n",
            "error: 0.005700250000003707, prediction: 0.7244999999999755\n",
            "error: 0.00562500000000369, prediction: 0.7249999999999754\n",
            "error: 0.005550250000003674, prediction: 0.7254999999999754\n",
            "error: 0.005476000000003658, prediction: 0.7259999999999753\n",
            "error: 0.005402250000003641, prediction: 0.7264999999999753\n",
            "error: 0.005329000000003624, prediction: 0.7269999999999752\n",
            "error: 0.005256250000003607, prediction: 0.7274999999999752\n",
            "error: 0.00518400000000359, prediction: 0.7279999999999751\n",
            "error: 0.005112250000003573, prediction: 0.7284999999999751\n",
            "error: 0.0050410000000035565, prediction: 0.728999999999975\n",
            "error: 0.004970250000003539, prediction: 0.729499999999975\n",
            "error: 0.004900000000003521, prediction: 0.7299999999999749\n",
            "error: 0.004830250000003504, prediction: 0.7304999999999748\n",
            "error: 0.004761000000003486, prediction: 0.7309999999999748\n",
            "error: 0.004692250000003469, prediction: 0.7314999999999747\n",
            "error: 0.004624000000003451, prediction: 0.7319999999999747\n",
            "error: 0.0045562500000034326, prediction: 0.7324999999999746\n",
            "error: 0.004489000000003415, prediction: 0.7329999999999746\n",
            "error: 0.0044222500000033966, prediction: 0.7334999999999745\n",
            "error: 0.004356000000003378, prediction: 0.7339999999999745\n",
            "error: 0.00429025000000336, prediction: 0.7344999999999744\n",
            "error: 0.0042250000000033415, prediction: 0.7349999999999743\n",
            "error: 0.004160250000003323, prediction: 0.7354999999999743\n",
            "error: 0.0040960000000033045, prediction: 0.7359999999999742\n",
            "error: 0.004032250000003285, prediction: 0.7364999999999742\n",
            "error: 0.003969000000003267, prediction: 0.7369999999999741\n",
            "error: 0.003906250000003247, prediction: 0.7374999999999741\n",
            "error: 0.003844000000003228, prediction: 0.737999999999974\n",
            "error: 0.003782250000003209, prediction: 0.738499999999974\n",
            "error: 0.0037210000000031896, prediction: 0.7389999999999739\n",
            "error: 0.00366025000000317, prediction: 0.7394999999999738\n",
            "error: 0.0036000000000031506, prediction: 0.7399999999999738\n",
            "error: 0.0035402500000031307, prediction: 0.7404999999999737\n",
            "error: 0.003481000000003111, prediction: 0.7409999999999737\n",
            "error: 0.0034222500000030912, prediction: 0.7414999999999736\n",
            "error: 0.003364000000003071, prediction: 0.7419999999999736\n",
            "error: 0.003306250000003051, prediction: 0.7424999999999735\n",
            "error: 0.0032490000000030307, prediction: 0.7429999999999735\n",
            "error: 0.0031922500000030104, prediction: 0.7434999999999734\n",
            "error: 0.0031360000000029897, prediction: 0.7439999999999733\n",
            "error: 0.003080250000002969, prediction: 0.7444999999999733\n",
            "error: 0.0030250000000029485, prediction: 0.7449999999999732\n",
            "error: 0.0029702500000029276, prediction: 0.7454999999999732\n",
            "error: 0.0029160000000029067, prediction: 0.7459999999999731\n",
            "error: 0.002862250000002886, prediction: 0.7464999999999731\n",
            "error: 0.0028090000000028648, prediction: 0.746999999999973\n",
            "error: 0.0027562500000028437, prediction: 0.747499999999973\n",
            "error: 0.002704000000002822, prediction: 0.7479999999999729\n",
            "error: 0.002652250000002801, prediction: 0.7484999999999729\n",
            "error: 0.002601000000002779, prediction: 0.7489999999999728\n",
            "error: 0.0025502500000027573, prediction: 0.7494999999999727\n",
            "error: 0.0025000000000027357, prediction: 0.7499999999999727\n",
            "error: 0.0024502500000027137, prediction: 0.7504999999999726\n",
            "error: 0.0024010000000026918, prediction: 0.7509999999999726\n",
            "error: 0.0023522500000026695, prediction: 0.7514999999999725\n",
            "error: 0.0023040000000026472, prediction: 0.7519999999999725\n",
            "error: 0.002256250000002625, prediction: 0.7524999999999724\n",
            "error: 0.0022090000000026025, prediction: 0.7529999999999724\n",
            "error: 0.00216225000000258, prediction: 0.7534999999999723\n",
            "error: 0.0021160000000025572, prediction: 0.7539999999999722\n",
            "error: 0.0020702500000025345, prediction: 0.7544999999999722\n",
            "error: 0.0020250000000025118, prediction: 0.7549999999999721\n",
            "error: 0.0019802500000024887, prediction: 0.7554999999999721\n",
            "error: 0.0019360000000024655, prediction: 0.755999999999972\n",
            "error: 0.0018922500000024423, prediction: 0.756499999999972\n",
            "error: 0.0018490000000024188, prediction: 0.7569999999999719\n",
            "error: 0.0018062500000023956, prediction: 0.7574999999999719\n",
            "error: 0.001764000000002372, prediction: 0.7579999999999718\n",
            "error: 0.0017222500000023482, prediction: 0.7584999999999718\n",
            "error: 0.0016810000000023245, prediction: 0.7589999999999717\n",
            "error: 0.0016402500000023007, prediction: 0.7594999999999716\n",
            "error: 0.0016000000000022767, prediction: 0.7599999999999716\n",
            "error: 0.0015602500000022525, prediction: 0.7604999999999715\n",
            "error: 0.0015210000000022283, prediction: 0.7609999999999715\n",
            "error: 0.001482250000002204, prediction: 0.7614999999999714\n",
            "error: 0.0014440000000021794, prediction: 0.7619999999999714\n",
            "error: 0.001406250000002155, prediction: 0.7624999999999713\n",
            "error: 0.0013690000000021302, prediction: 0.7629999999999713\n",
            "error: 0.0013322500000021056, prediction: 0.7634999999999712\n",
            "error: 0.0012960000000020806, prediction: 0.7639999999999711\n",
            "error: 0.0012602500000020557, prediction: 0.7644999999999711\n",
            "error: 0.0012250000000020305, prediction: 0.764999999999971\n",
            "error: 0.0011902500000020052, prediction: 0.765499999999971\n",
            "error: 0.00115600000000198, prediction: 0.7659999999999709\n",
            "error: 0.0011222500000019546, prediction: 0.7664999999999709\n",
            "error: 0.0010890000000019291, prediction: 0.7669999999999708\n",
            "error: 0.0010562500000019033, prediction: 0.7674999999999708\n",
            "error: 0.0010240000000018776, prediction: 0.7679999999999707\n",
            "error: 0.0009922500000018517, prediction: 0.7684999999999707\n",
            "error: 0.0009610000000018258, prediction: 0.7689999999999706\n",
            "error: 0.0009302500000017998, prediction: 0.7694999999999705\n",
            "error: 0.0009000000000017735, prediction: 0.7699999999999705\n",
            "error: 0.0008702500000017472, prediction: 0.7704999999999704\n",
            "error: 0.0008410000000017208, prediction: 0.7709999999999704\n",
            "error: 0.0008122500000016942, prediction: 0.7714999999999703\n",
            "error: 0.0007840000000016676, prediction: 0.7719999999999703\n",
            "error: 0.0007562500000016409, prediction: 0.7724999999999702\n",
            "error: 0.000729000000001614, prediction: 0.7729999999999702\n",
            "error: 0.000702250000001587, prediction: 0.7734999999999701\n",
            "error: 0.0006760000000015599, prediction: 0.77399999999997\n",
            "error: 0.0006502500000015327, prediction: 0.77449999999997\n",
            "error: 0.0006250000000015054, prediction: 0.7749999999999699\n",
            "error: 0.0006002500000014781, prediction: 0.7754999999999699\n",
            "error: 0.0005760000000014506, prediction: 0.7759999999999698\n",
            "error: 0.0005522500000014229, prediction: 0.7764999999999698\n",
            "error: 0.0005290000000013951, prediction: 0.7769999999999697\n",
            "error: 0.0005062500000013673, prediction: 0.7774999999999697\n",
            "error: 0.00048400000000133937, prediction: 0.7779999999999696\n",
            "error: 0.0004622500000013113, prediction: 0.7784999999999695\n",
            "error: 0.0004410000000012831, prediction: 0.7789999999999695\n",
            "error: 0.0004202500000012548, prediction: 0.7794999999999694\n",
            "error: 0.0004000000000012264, prediction: 0.7799999999999694\n",
            "error: 0.0003802500000011979, prediction: 0.7804999999999693\n",
            "error: 0.00036100000000116925, prediction: 0.7809999999999693\n",
            "error: 0.0003422500000011405, prediction: 0.7814999999999692\n",
            "error: 0.0003240000000011117, prediction: 0.7819999999999692\n",
            "error: 0.00030625000000108273, prediction: 0.7824999999999691\n",
            "error: 0.00028900000000105366, prediction: 0.782999999999969\n",
            "error: 0.0002722500000010245, prediction: 0.783499999999969\n",
            "error: 0.00025600000000099523, prediction: 0.7839999999999689\n",
            "error: 0.00024025000000096582, prediction: 0.7844999999999689\n",
            "error: 0.0002250000000009363, prediction: 0.7849999999999688\n",
            "error: 0.0002102500000009067, prediction: 0.7854999999999688\n",
            "error: 0.00019600000000087698, prediction: 0.7859999999999687\n",
            "error: 0.00018225000000084715, prediction: 0.7864999999999687\n",
            "error: 0.0001690000000008172, prediction: 0.7869999999999686\n",
            "error: 0.00015625000000078716, prediction: 0.7874999999999686\n",
            "error: 0.000144000000000757, prediction: 0.7879999999999685\n",
            "error: 0.0001322500000007267, prediction: 0.7884999999999684\n",
            "error: 0.00012100000000069633, prediction: 0.7889999999999684\n",
            "error: 0.00011025000000066583, prediction: 0.7894999999999683\n",
            "error: 0.00010000000000063523, prediction: 0.7899999999999683\n",
            "error: 9.025000000060451e-05, prediction: 0.7904999999999682\n",
            "error: 8.100000000057368e-05, prediction: 0.7909999999999682\n",
            "error: 7.225000000054275e-05, prediction: 0.7914999999999681\n",
            "error: 6.40000000005117e-05, prediction: 0.7919999999999681\n",
            "error: 5.625000000048055e-05, prediction: 0.792499999999968\n",
            "error: 4.9000000000449285e-05, prediction: 0.792999999999968\n",
            "error: 4.225000000041791e-05, prediction: 0.7934999999999679\n",
            "error: 3.6000000000386424e-05, prediction: 0.7939999999999678\n",
            "error: 3.0250000000354826e-05, prediction: 0.7944999999999678\n",
            "error: 2.500000000032312e-05, prediction: 0.7949999999999677\n",
            "error: 2.0250000000291302e-05, prediction: 0.7954999999999677\n",
            "error: 1.6000000000259378e-05, prediction: 0.7959999999999676\n",
            "error: 1.225000000022734e-05, prediction: 0.7964999999999676\n",
            "error: 9.000000000195194e-06, prediction: 0.7969999999999675\n",
            "error: 6.250000000162936e-06, prediction: 0.7974999999999675\n",
            "error: 4.000000000130569e-06, prediction: 0.7979999999999674\n",
            "error: 2.2500000000980924e-06, prediction: 0.7984999999999673\n",
            "error: 1.000000000065505e-06, prediction: 0.7989999999999673\n",
            "error: 2.5000000003280753e-07, prediction: 0.7994999999999672\n",
            "error: 1.0799505792475652e-27, prediction: 0.7999999999999672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9zPDlZ6_tzo"
      },
      "source": [
        "#### Problems with this method:\n",
        "1. It's inefficient.\n",
        "2. Sometimes it's impossible to predict the exact goal prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKPvEnGNAK3X"
      },
      "source": [
        "#### Calculating both direction and amount from error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqNtAhL1zl5",
        "outputId": "3deae3cd-c48c-40fd-cbc2-3691828cb89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "weight = 0.5\n",
        "goal_pred = 0.8\n",
        "input = 0.5\n",
        "\n",
        "for iteration in range(20):\n",
        "  pred = input * weight\n",
        "  error = (pred - goal_pred) ** 2\n",
        "  direction_and_amount = (pred - goal_pred) * input # gradient descent\n",
        "  weight = weight - direction_and_amount\n",
        "  print(\"Error: {} Prediction: {}\".format(error, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.30250000000000005 Prediction: 0.25\n",
            "Error: 0.17015625000000004 Prediction: 0.3875\n",
            "Error: 0.095712890625 Prediction: 0.49062500000000003\n",
            "Error: 0.05383850097656251 Prediction: 0.56796875\n",
            "Error: 0.03028415679931642 Prediction: 0.6259765625\n",
            "Error: 0.0170348381996155 Prediction: 0.669482421875\n",
            "Error: 0.00958209648728372 Prediction: 0.70211181640625\n",
            "Error: 0.005389929274097089 Prediction: 0.7265838623046875\n",
            "Error: 0.0030318352166796153 Prediction: 0.7449378967285156\n",
            "Error: 0.0017054073093822882 Prediction: 0.7587034225463867\n",
            "Error: 0.0009592916115275371 Prediction: 0.76902756690979\n",
            "Error: 0.0005396015314842384 Prediction: 0.7767706751823426\n",
            "Error: 0.000303525861459885 Prediction: 0.7825780063867569\n",
            "Error: 0.00017073329707118678 Prediction: 0.7869335047900676\n",
            "Error: 9.603747960254256e-05 Prediction: 0.7902001285925507\n",
            "Error: 5.402108227642978e-05 Prediction: 0.7926500964444131\n",
            "Error: 3.038685878049206e-05 Prediction: 0.7944875723333098\n",
            "Error: 1.7092608064027242e-05 Prediction: 0.7958656792499823\n",
            "Error: 9.614592036015323e-06 Prediction: 0.7968992594374867\n",
            "Error: 5.408208020258491e-06 Prediction: 0.7976744445781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJQcrw6zCmFG"
      },
      "source": [
        "#### What is direction and amount:\n",
        "\n",
        "It represents how we want to change weight. The first part is \"pure error\" and second part is \"scaling, negative reversal and stopping\"\n",
        "\n",
        "#### What is pure error?\n",
        "\n",
        "(pred - goal_pred) is pure error in the code. It indicates raw amount and direction we missed. If this is a positive number, you predicted too high, and vice versa. If it's a big number we missed by a big amount.\n",
        "\n",
        "#### What are scaling, negative reversal, and stopping?\n",
        "**Stopping:** Stopping is the first effect on pure error caused by multiplying it by input. If input is 0, then it will force \"direction_and_amount\" to also be 0.\n",
        "\n",
        "**Negative Reversal:** Normally when input is positive, moving weight upwards makes the prediction move upward. But if input is negative, moving weight up makes the prediction go down. It's reversed. To address this we multiply the pure error with input so that direction of weight is correct even if input is negative.\n",
        "\n",
        "**Scaling:** If input is big weight update should also be big. (side effects of it will be fixed by including \"alpha\" later).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmeQB-twF_NZ"
      },
      "source": [
        "### One iteration of Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6d9AttAA7aU"
      },
      "source": [
        "weight = 0.0\n",
        "goal_pred = 0.8\n",
        "input = 0.5\n",
        "alpha = 0.1\n",
        "\n",
        "pred = input * weight # these lines have secrets\n",
        "error = (pred - goal_pred) ** 2 # these lines have secrets\n",
        "delta = (pred - goal_pred)\n",
        "weight_delta = delta * input\n",
        "weight -= weight_delta * alpha\n",
        "\n",
        "#we can write those lines like:\n",
        "error = ((input * weight) - goal_pred) ** 2\n",
        "# input and goal_pred are constants here, and error and weights are only variables\n",
        "# Which means for any input and goal_pred, an exact relationship is defined between error and weight."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHhNQfVKsE6L"
      },
      "source": [
        "### Derivatives\n",
        "\n",
        "**Take one:** \n",
        "\n",
        "Assume we have an equation like below\n",
        "\n",
        "superman_strength = spiderman_strength * 2\n",
        "\n",
        "We can say \"superman_strength\" is a function of \"spiderman_strength\" and the definition of this formula could be \"When I increase spiderman_strength how much superman_strength increases? It's called derivative.\"\n",
        "\n",
        "So \"2\" here in the above formula is derivative. (superman_strength / spiderman_strength)\n",
        "\n",
        "**Take Two:** \n",
        "\n",
        "The other way to define a derivative is \"Derivative is the slope at a point on a line or curve.\"\n",
        "\n",
        "If you plot \"error = ((input * weight) - goal_pred) ** 2\" this function, the plot will look like a big U-shaped curve and there will be a point in the middle where error will be 0. Also right of that point, the slope of the line will be positive and to the left of that point, the slope of the line will be negative. And farther away from the \"goal weight\" you move, the steeper the slope gets. \n",
        "\n",
        "These properties are very useful. The slope's sign gives you direction and the slope's steepness gives you amount and we can use both of these to helo find the goal weight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj8JiHUaws0o"
      },
      "source": [
        "### How to use derivative to learn\n",
        "weight_delta is our derivative.\n",
        "\n",
        "**What is the difference between error and derivative of error and weight?**\n",
        "error is a measure of how much we missed. The derivative defines a relationship between error and weight. It tells us how much we missed for a specific weight or how much changing the weight contributed to error.\n",
        "\n",
        "**The slope of a line or curve always point in the opposite direction of the lowest point of the line or curve. So if we have negative slope, we increase wight to find minimum of error.**\n",
        "\n",
        "So how do we use derivative to find the error minimum? We move the opposite direction of the slope - the opposite direction of the derivative. We can take each weight value, calculate it's derivative w.r.t. to error, and then change weight in the opposite direction of that slope and that will move us to the minimum.\n",
        "\n",
        "**A derivative gives us the relationship between any two variables in a function. We use the derivative to find the relationship between any weight and error. And then we move the weight in the opposite direction of the derivative to find the lowest error.** \n",
        "\n",
        "This method of learning is called **gradient descent**. We move the weight value opposite to the gradient value, which reduces error to 0. We increase the weight when you have a negative gradient and vice versa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1xVNqnM2eSJ"
      },
      "source": [
        "### Gradient Descent Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9fkA7biHALL",
        "outputId": "0fbd8b62-71e1-4001-9092-635c7261ae99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "weight = 0.5\n",
        "goal_pred = 0.8\n",
        "input = 0.5\n",
        "\n",
        "for iteration in range(20):\n",
        "  pred = input * weight\n",
        "  error = (pred - goal_pred) ** 2\n",
        "  delta = pred - goal_pred\n",
        "  weight_delta = delta * input # 'input' is derivative. rate of change in weight (weight_delta) w.r.t. error change(delta).\n",
        "  weight -= weight_delta\n",
        "  print(\"Error: {} Prediction: {}\".format(error, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.30250000000000005 Prediction: 0.25\n",
            "Error: 0.17015625000000004 Prediction: 0.3875\n",
            "Error: 0.095712890625 Prediction: 0.49062500000000003\n",
            "Error: 0.05383850097656251 Prediction: 0.56796875\n",
            "Error: 0.03028415679931642 Prediction: 0.6259765625\n",
            "Error: 0.0170348381996155 Prediction: 0.669482421875\n",
            "Error: 0.00958209648728372 Prediction: 0.70211181640625\n",
            "Error: 0.005389929274097089 Prediction: 0.7265838623046875\n",
            "Error: 0.0030318352166796153 Prediction: 0.7449378967285156\n",
            "Error: 0.0017054073093822882 Prediction: 0.7587034225463867\n",
            "Error: 0.0009592916115275371 Prediction: 0.76902756690979\n",
            "Error: 0.0005396015314842384 Prediction: 0.7767706751823426\n",
            "Error: 0.000303525861459885 Prediction: 0.7825780063867569\n",
            "Error: 0.00017073329707118678 Prediction: 0.7869335047900676\n",
            "Error: 9.603747960254256e-05 Prediction: 0.7902001285925507\n",
            "Error: 5.402108227642978e-05 Prediction: 0.7926500964444131\n",
            "Error: 3.038685878049206e-05 Prediction: 0.7944875723333098\n",
            "Error: 1.7092608064027242e-05 Prediction: 0.7958656792499823\n",
            "Error: 9.614592036015323e-06 Prediction: 0.7968992594374867\n",
            "Error: 5.408208020258491e-06 Prediction: 0.7976744445781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KmQALW05SSy"
      },
      "source": [
        "### Divergence\n",
        "Sometimes neural networks explode in value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVZBj1Xn32VP",
        "outputId": "1b3a3c69-c7bb-4e09-b1ba-c127a0506ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# change the input to 2 from 0.5\n",
        "weight = 0.5\n",
        "goal_pred = 0.8\n",
        "input = 2\n",
        "\n",
        "for iteration in range(20):\n",
        "  pred = input * weight\n",
        "  error = (pred - goal_pred) ** 2\n",
        "  delta = pred - goal_pred\n",
        "  weight_delta = delta * input\n",
        "  weight -= weight_delta\n",
        "  print(\"Error: {} Prediction: {}\".format(error, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.03999999999999998 Prediction: 1.0\n",
            "Error: 0.3599999999999998 Prediction: 0.20000000000000018\n",
            "Error: 3.2399999999999984 Prediction: 2.5999999999999996\n",
            "Error: 29.159999999999986 Prediction: -4.599999999999999\n",
            "Error: 262.4399999999999 Prediction: 16.999999999999996\n",
            "Error: 2361.959999999998 Prediction: -47.79999999999998\n",
            "Error: 21257.639999999978 Prediction: 146.59999999999994\n",
            "Error: 191318.75999999983 Prediction: -436.5999999999998\n",
            "Error: 1721868.839999999 Prediction: 1312.9999999999995\n",
            "Error: 15496819.559999991 Prediction: -3935.799999999999\n",
            "Error: 139471376.03999993 Prediction: 11810.599999999997\n",
            "Error: 1255242384.3599997 Prediction: -35428.59999999999\n",
            "Error: 11297181459.239996 Prediction: 106288.99999999999\n",
            "Error: 101674633133.15994 Prediction: -318863.79999999993\n",
            "Error: 915071698198.4395 Prediction: 956594.5999999997\n",
            "Error: 8235645283785.954 Prediction: -2869780.599999999\n",
            "Error: 74120807554073.56 Prediction: 8609344.999999996\n",
            "Error: 667087267986662.1 Prediction: -25828031.799999986\n",
            "Error: 6003785411879960.0 Prediction: 77484098.59999996\n",
            "Error: 5.403406870691965e+16 Prediction: -232452292.5999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuQaY6ca6CDy"
      },
      "source": [
        "The explosion in the error was caused by the fact that we made the input larger.\n",
        "\n",
        "What happens when we have large weight update and a small error? The network overcorrects. If the new error is even bigger, the network overcorrects even more. This causes the phenomenon called divergence.\n",
        "\n",
        "How do we predict? By multilying input with weights. What if input is big? small change in weight will cause changes in prediction. The error is very sensitive to weight or derivative (input) is really big."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdSzoMks6_vj"
      },
      "source": [
        "### Introducing alpha\n",
        "Simplest way to prevent overcorrecting weight updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktl2sSAh5ggO",
        "outputId": "b3885671-28b3-4ee0-fcd8-0dd66169dd1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "weight = 0.5\n",
        "goal_pred = 0.8\n",
        "input = 2\n",
        "alpha = 0.1\n",
        "\n",
        "for iteration in range(20):\n",
        "  pred = input * weight\n",
        "  error = (pred - goal_pred) ** 2\n",
        "  delta = pred - goal_pred\n",
        "  weight_delta = delta * input\n",
        "  weight -= weight_delta * alpha\n",
        "  print(\"Error: {} Prediction: {}\".format(error, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.03999999999999998 Prediction: 1.0\n",
            "Error: 0.0144 Prediction: 0.92\n",
            "Error: 0.005183999999999993 Prediction: 0.872\n",
            "Error: 0.0018662400000000014 Prediction: 0.8432000000000001\n",
            "Error: 0.0006718464000000028 Prediction: 0.8259200000000001\n",
            "Error: 0.00024186470400000033 Prediction: 0.815552\n",
            "Error: 8.70712934399997e-05 Prediction: 0.8093312\n",
            "Error: 3.134566563839939e-05 Prediction: 0.80559872\n",
            "Error: 1.1284439629823931e-05 Prediction: 0.803359232\n",
            "Error: 4.062398266736526e-06 Prediction: 0.8020155392\n",
            "Error: 1.4624633760252567e-06 Prediction: 0.8012093235200001\n",
            "Error: 5.264868153690924e-07 Prediction: 0.8007255941120001\n",
            "Error: 1.8953525353291194e-07 Prediction: 0.8004353564672001\n",
            "Error: 6.82326912718715e-08 Prediction: 0.8002612138803201\n",
            "Error: 2.456376885786678e-08 Prediction: 0.8001567283281921\n",
            "Error: 8.842956788836216e-09 Prediction: 0.8000940369969153\n",
            "Error: 3.1834644439835434e-09 Prediction: 0.8000564221981492\n",
            "Error: 1.1460471998340758e-09 Prediction: 0.8000338533188895\n",
            "Error: 4.125769919393652e-10 Prediction: 0.8000203119913337\n",
            "Error: 1.485277170987127e-10 Prediction: 0.8000121871948003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9CMIEUWg_xX"
      },
      "source": [
        "### Chapter 5\n",
        "### Learning multiple weights at a time: Generalizing gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB0AX9NghYE2"
      },
      "source": [
        "#### Gradient descent learning with multiple inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAQYSPpjXQmv",
        "outputId": "dc6d627d-232a-4c1b-c94c-739173d8c28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "def w_sum(a, b):\n",
        "  assert(len(a) == len(b))\n",
        "  output = 0\n",
        "  for i in range(len(a)):\n",
        "    output += (a[i] * b[i])\n",
        "  return output\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  pred = w_sum(input, weights)\n",
        "  return pred\n",
        "\n",
        "def ele_mul(number, vector):\n",
        "  output = [0, 0, 0]\n",
        "  assert(len(output) == len(vector))\n",
        "  for i in range(len(vector)):\n",
        "    output[i] = number * vector[i]\n",
        "  return output\n",
        "\n",
        "toes = np.array([8.5, 9.5, 9.9, 9.0]) \n",
        "wlrec = np.array([0.65, 0.8, 0.8, 0.9]) \n",
        "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
        "\n",
        "win_or_lose_binary = [1, 1, 0, 1]\n",
        "true = win_or_lose_binary[0]\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "alpha = 0.01\n",
        "weights = [0.1, 0.2, -.1]\n",
        "\n",
        "for i in range(3):\n",
        "  pred = neural_network(input, weights)\n",
        "  error = (pred - true) ** 2\n",
        "  delta = pred - true\n",
        "  weight_deltas = ele_mul(delta, input)\n",
        "  print(\"Iteration: {}\".format(i+1))\n",
        "  print(\"Pred: {}\".format(pred))\n",
        "  print(\"Error: {}\".format(error))\n",
        "  print(\"Delta: {}\".format(delta))\n",
        "  print(\"Weights: {}\".format(weights))\n",
        "  print(\"weight Deltas:\")\n",
        "  print(weight_deltas)\n",
        "\n",
        "  for i in range(len(weights)):\n",
        "    weights[i] -= (alpha * weight_deltas[i])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1\n",
            "Pred: 0.8600000000000001\n",
            "Error: 0.01959999999999997\n",
            "Delta: -0.1399999999999999\n",
            "Weights: [0.1, 0.2, -0.1]\n",
            "weight Deltas:\n",
            "[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
            "Iteration: 2\n",
            "Pred: 0.9637574999999999\n",
            "Error: 0.0013135188062500048\n",
            "Delta: -0.036242500000000066\n",
            "Weights: [0.1119, 0.20091, -0.09832]\n",
            "weight Deltas:\n",
            "[-0.30806125000000056, -0.023557625000000044, -0.04349100000000008]\n",
            "Iteration: 3\n",
            "Pred: 0.9906177228125002\n",
            "Error: 8.802712522307997e-05\n",
            "Delta: -0.009382277187499843\n",
            "Weights: [0.11498061250000001, 0.20114557625, -0.09788509000000001]\n",
            "weight Deltas:\n",
            "[-0.07974935609374867, -0.006098480171874899, -0.011258732624999811]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q66VdqNenL2V"
      },
      "source": [
        "#### Gradient descent learning with multiple outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zSNjKx-j5zT",
        "outputId": "80698c1f-981b-4ef7-9400-4a1a5e9a5f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "weights = [0.3, 0.2, 0.9]\n",
        "\n",
        "def ele_mul(number, vector):\n",
        "  output = [0, 0, 0]\n",
        "  assert(len(output) == len(vector))\n",
        "  for i in range(len(vector)):\n",
        "    output[i] = number * vector[i]\n",
        "  return output\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  pred = ele_mul(input, weights)\n",
        "  return pred\n",
        "\n",
        "\n",
        "wlrec = [0.65, 1.0, 1.0, 0.9]\n",
        "\n",
        "hurt = [0.1, 0.0, 0.0, 0.1]\n",
        "win = [1,1,0,1]\n",
        "sad = [0.1, 0.0, 0.1, 0.2]\n",
        "\n",
        "input = wlrec[0]\n",
        "true = [hurt[0], win[0], sad[0]]\n",
        "\n",
        "pred = neural_network(input, weights)\n",
        "\n",
        "error = [0, 0, 0]\n",
        "delta = [0, 0, 0]\n",
        "\n",
        "for i in range(len(true)):\n",
        "  error[i] = (pred[i] - true[i]) ** 2\n",
        "  delta[i] = pred[i] - true[i]\n",
        "\n",
        "weight_deltas = ele_mul(input, delta)\n",
        "alpha = 0.1\n",
        "\n",
        "for i in range(len(weights)):\n",
        "  weights[i] -= (weight_deltas[i] * alpha)\n",
        "\n",
        "print(\"weights:\" + str(weights))\n",
        "print(\"Weight deltas:\" + str(weight_deltas))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights:[0.293825, 0.25655, 0.868475]\n",
            "Weight deltas:[0.061750000000000006, -0.5655, 0.3152500000000001]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaXZ8AE_rEtV"
      },
      "source": [
        "#### Gradient descent with multiple inputs and outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHXeYHfxqYtn",
        "outputId": "d6a4bce1-f3c5-44d5-e447-25b4b1d83660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "weights = np.array([[0.1, 0.1, -0.3],\n",
        "           [0.1, 0.2, 0.0],\n",
        "           [0.0, 1.3, 0.1]])\n",
        "\n",
        "def w_sum(a, b):\n",
        "  assert(len(a) == len(b))\n",
        "  output = 0\n",
        "\n",
        "  for i in range(len(a)):\n",
        "    output += a[i] * b[i]\n",
        "  return output\n",
        "\n",
        "def vect_mat_mul(vect, matrix):\n",
        "  assert(len(vect) == len(matrix))\n",
        "  output = [0, 0, 0]\n",
        "  for i in range(len(vect)):\n",
        "    output[i] = w_sum(vect, matrix[i])\n",
        "  return output\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  pred = vect_mat_mul(input, weights)\n",
        "  return pred\n",
        "\n",
        "def outer_prod(vec_a, vec_b):\n",
        "  a = np.array(vec_a)\n",
        "  b = np.array(vec_b)\n",
        "  c = np.dot(a,b)\n",
        "  return c\n",
        "\n",
        "toes = [8.5, 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65,0.8, 0.8, 0.9]\n",
        "nfans = [1.2, 1.3, 0.5, 1.0]\n",
        "\n",
        "hurt = [0.1, 0.0, 0.0, 0.1]\n",
        "win = [1,1,0,1]\n",
        "sad = [0.1, 0.0, 0.1, 0.2]\n",
        "\n",
        "alpha = 0.01\n",
        "\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "true = [hurt[0], win[0], sad[0]]\n",
        "error = [0, 0, 0]\n",
        "delta = [0, 0, 0]\n",
        "\n",
        "for i in range(5):\n",
        "  pred = neural_network(input, weights)\n",
        "\n",
        "  for i in range(len(true)):\n",
        "    error[i] = (pred[i] - true[i]) ** 2\n",
        "    delta = pred[i] - true[i]\n",
        "\n",
        "  weight_deltas = outer_prod(input, delta)\n",
        "  weights = weights * alpha\n",
        "  print(error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20702500000000007, 0.0003999999999999963, 0.7482250000000001]\n",
            "[0.008920802500000002, 0.9804960399999999, 0.0081631225]\n",
            "[0.009988903080250001, 0.999804009604, 0.009980709312250001]\n",
            "[0.009999889000308026, 0.9999980400009604, 0.009999807000931225]\n",
            "[0.009999998890000032, 0.9999999804, 0.009999998070000096]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ8M437Ae6EE"
      },
      "source": [
        "### Chapter 6: \n",
        "### Building your first deep neural network: Introduction to backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzPuR-sVUbyd",
        "outputId": "d87b1d15-afa8-4423-acf5-319e5066fa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# streetlight problem\n",
        "import numpy as np\n",
        "weights = np.array([0.5, 0.48, -0.7])\n",
        "alpha = 0.1\n",
        "\n",
        "streetlights = np.array([[ 1, 0, 1 ],\n",
        "                          [ 0, 1, 1 ],\n",
        "                          [ 0, 0, 1 ],\n",
        "                          [ 1, 1, 1 ],\n",
        "                          [ 0, 1, 1 ],\n",
        "                          [ 1, 0, 1 ]])\n",
        "\n",
        "walk_vs_stop = np.array([0,1,0,1,1,0])\n",
        "input = streetlights[0]\n",
        "goal_prediction = walk_vs_stop[0]\n",
        "\n",
        "for i in range(20):\n",
        "  prediction = np.dot(input, weights)\n",
        "  error = (goal_prediction - prediction) ** 2\n",
        "  delta = prediction - goal_prediction\n",
        "  weights = weights - (alpha * (input * delta))\n",
        "  print(\"Error: {}, Prediction: {}\".format(error,prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.03999999999999998, Prediction: -0.19999999999999996\n",
            "Error: 0.025599999999999973, Prediction: -0.15999999999999992\n",
            "Error: 0.01638399999999997, Prediction: -0.1279999999999999\n",
            "Error: 0.010485759999999964, Prediction: -0.10239999999999982\n",
            "Error: 0.006710886399999962, Prediction: -0.08191999999999977\n",
            "Error: 0.004294967295999976, Prediction: -0.06553599999999982\n",
            "Error: 0.002748779069439994, Prediction: -0.05242879999999994\n",
            "Error: 0.0017592186044416036, Prediction: -0.04194304000000004\n",
            "Error: 0.0011258999068426293, Prediction: -0.03355443200000008\n",
            "Error: 0.0007205759403792803, Prediction: -0.02684354560000002\n",
            "Error: 0.0004611686018427356, Prediction: -0.021474836479999926\n",
            "Error: 0.0002951479051793508, Prediction: -0.01717986918399994\n",
            "Error: 0.00018889465931478573, Prediction: -0.013743895347199997\n",
            "Error: 0.00012089258196146188, Prediction: -0.010995116277759953\n",
            "Error: 7.737125245533561e-05, Prediction: -0.008796093022207963\n",
            "Error: 4.951760157141604e-05, Prediction: -0.007036874417766459\n",
            "Error: 3.169126500570676e-05, Prediction: -0.0056294995342132115\n",
            "Error: 2.028240960365233e-05, Prediction: -0.004503599627370569\n",
            "Error: 1.298074214633813e-05, Prediction: -0.003602879701896544\n",
            "Error: 8.307674973656916e-06, Prediction: -0.002882303761517324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOiggiwfVOhI",
        "outputId": "53092488-0310-4052-eaa2-446ad29f54f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#learning whole dataset\n",
        "import numpy as np\n",
        "weights = np.array([0.5, 0.48, -0.7])\n",
        "alpha = 0.1\n",
        "\n",
        "streetlights = np.array([[ 1, 0, 1 ],\n",
        "                          [ 0, 1, 1 ],\n",
        "                          [ 0, 0, 1 ],\n",
        "                          [ 1, 1, 1 ],\n",
        "                          [ 0, 1, 1 ],\n",
        "                          [ 1, 0, 1 ]])\n",
        "\n",
        "walk_vs_stop = np.array([0,1,0,1,1,0])\n",
        "input = streetlights[0]\n",
        "goal_prediction = walk_vs_stop[0]\n",
        "\n",
        "for i in range(40):\n",
        "  error_for_all_lights = 0\n",
        "  for row_index in range(len(walk_vs_stop)):\n",
        "    input = streetlights[row_index]\n",
        "    goal_prediction = walk_vs_stop[row_index]\n",
        "    prediction = np.dot(input, weights)\n",
        "    error = (goal_prediction - prediction) ** 2\n",
        "    error_for_all_lights += error\n",
        "    delta = prediction - goal_prediction\n",
        "    weights = weights - (alpha * (input * delta))\n",
        "    print(\"Prediction: {}\".format(prediction))\n",
        "  print(\"Error: {} \\n\".format(error_for_all_lights))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: -0.19999999999999996\n",
            "Prediction: -0.19999999999999996\n",
            "Prediction: -0.5599999999999999\n",
            "Prediction: 0.6160000000000001\n",
            "Prediction: 0.17279999999999995\n",
            "Prediction: 0.17552\n",
            "Error: 2.6561231104 \n",
            "\n",
            "Prediction: 0.14041599999999999\n",
            "Prediction: 0.3066464\n",
            "Prediction: -0.34513824\n",
            "Prediction: 1.006637344\n",
            "Prediction: 0.4785034751999999\n",
            "Prediction: 0.26700416768\n",
            "Error: 0.9628701776715985 \n",
            "\n",
            "Prediction: 0.213603334144\n",
            "Prediction: 0.5347420299776\n",
            "Prediction: -0.26067345110016\n",
            "Prediction: 1.1319428845096962\n",
            "Prediction: 0.6274723921901568\n",
            "Prediction: 0.25433999330650114\n",
            "Error: 0.5509165866836797 \n",
            "\n",
            "Prediction: 0.20347199464520088\n",
            "Prediction: 0.6561967149569552\n",
            "Prediction: -0.221948503950995\n",
            "Prediction: 1.166258650532124\n",
            "Prediction: 0.7139004922542389\n",
            "Prediction: 0.21471099528371604\n",
            "Error: 0.36445836852222424 \n",
            "\n",
            "Prediction: 0.17176879622697283\n",
            "Prediction: 0.7324724146523222\n",
            "Prediction: -0.19966478845083285\n",
            "Prediction: 1.1697769945341199\n",
            "Prediction: 0.7719890116601171\n",
            "Prediction: 0.17297997428859369\n",
            "Error: 0.2516768662079895 \n",
            "\n",
            "Prediction: 0.13838397943087496\n",
            "Prediction: 0.7864548139561468\n",
            "Prediction: -0.1836567869927348\n",
            "Prediction: 1.163248019006011\n",
            "Prediction: 0.8148799260629888\n",
            "Prediction: 0.1362897844408577\n",
            "Error: 0.17797575048089034 \n",
            "\n",
            "Prediction: 0.10903182755268614\n",
            "Prediction: 0.8273717796510367\n",
            "Prediction: -0.17037324196481937\n",
            "Prediction: 1.1537962739591756\n",
            "Prediction: 0.8481754931254761\n",
            "Prediction: 0.1059488041691444\n",
            "Error: 0.12864460733422164 \n",
            "\n",
            "Prediction: 0.0847590433353155\n",
            "Prediction: 0.859469609749935\n",
            "Prediction: -0.1585508402022421\n",
            "Prediction: 1.1438418857156731\n",
            "Prediction: 0.8746623946770374\n",
            "Prediction: 0.08148074110264475\n",
            "Error: 0.09511036950476208 \n",
            "\n",
            "Prediction: 0.06518459288211581\n",
            "Prediction: 0.8850633823431538\n",
            "Prediction: -0.14771905585408038\n",
            "Prediction: 1.1341830033853888\n",
            "Prediction: 0.8959860107828534\n",
            "Prediction: 0.0619780399014222\n",
            "Error: 0.07194564247043436 \n",
            "\n",
            "Prediction: 0.04958243192113776\n",
            "Prediction: 0.9056327614440267\n",
            "Prediction: -0.13768337501215525\n",
            "Prediction: 1.1250605910610996\n",
            "Prediction: 0.9132624284442169\n",
            "Prediction: 0.04653264583708144\n",
            "Error: 0.05564914990717743 \n",
            "\n",
            "Prediction: 0.03722611666966513\n",
            "Prediction: 0.922234066504699\n",
            "Prediction: -0.12834662236261596\n",
            "Prediction: 1.116526024487899\n",
            "Prediction: 0.9273167105424409\n",
            "Prediction: 0.03435527296969987\n",
            "Error: 0.04394763937673939 \n",
            "\n",
            "Prediction: 0.027484218375759886\n",
            "Prediction: 0.9356694192994068\n",
            "Prediction: -0.11964712469387503\n",
            "Prediction: 1.1085678053734553\n",
            "Prediction: 0.9387866868342218\n",
            "Prediction: 0.024792915481941458\n",
            "Error: 0.035357967050948465 \n",
            "\n",
            "Prediction: 0.019834332385553155\n",
            "Prediction: 0.946566624680628\n",
            "Prediction: -0.11153724870006754\n",
            "Prediction: 1.1011550767549563\n",
            "Prediction: 0.948176009263518\n",
            "Prediction: 0.017315912033043404\n",
            "Error: 0.02890700056547436 \n",
            "\n",
            "Prediction: 0.013852729626434732\n",
            "Prediction: 0.9554239432448665\n",
            "Prediction: -0.10397589092234266\n",
            "Prediction: 1.0942524239871314\n",
            "Prediction: 0.9558862588907013\n",
            "Prediction: 0.011498267782398985\n",
            "Error: 0.023951660591138853 \n",
            "\n",
            "Prediction: 0.009198614225919194\n",
            "Prediction: 0.9626393189117293\n",
            "Prediction: -0.09692579020989642\n",
            "Prediction: 1.087824783849832\n",
            "Prediction: 0.9622390773804066\n",
            "Prediction: 0.006998674002545002\n",
            "Error: 0.020063105176016144 \n",
            "\n",
            "Prediction: 0.005598939202035996\n",
            "Prediction: 0.9685315005838672\n",
            "Prediction: -0.09035250869077546\n",
            "Prediction: 1.0818389613301889\n",
            "Prediction: 0.9674926590701334\n",
            "Prediction: 0.003544193999268516\n",
            "Error: 0.016952094519447087 \n",
            "\n",
            "Prediction: 0.0028353551994148157\n",
            "Prediction: 0.9733561723362383\n",
            "Prediction: -0.0842239920152223\n",
            "Prediction: 1.0762639960116431\n",
            "Prediction: 0.9718545378681842\n",
            "Prediction: 0.0009168131382832068\n",
            "Error: 0.014420818295271236 \n",
            "\n",
            "Prediction: 0.0007334505106265654\n",
            "Prediction: 0.9773186039296565\n",
            "Prediction: -0.07851033295953944\n",
            "Prediction: 1.0710711494147542\n",
            "Prediction: 0.9754916865567282\n",
            "Prediction: -0.0010574652271341245\n",
            "Error: 0.012331739998443648 \n",
            "\n",
            "Prediction: -0.0008459721817072885\n",
            "Prediction: 0.9805836929862668\n",
            "Prediction: -0.07318360881847627\n",
            "Prediction: 1.066233777045345\n",
            "Prediction: 0.9785385598617921\n",
            "Prediction: -0.0025173975573930946\n",
            "Error: 0.010587393171639842 \n",
            "\n",
            "Prediction: -0.002013918045914484\n",
            "Prediction: 0.9832839794497644\n",
            "Prediction: -0.06821774801198803\n",
            "Prediction: 1.0617271739912904\n",
            "Prediction: 0.9811035235627523\n",
            "Prediction: -0.0035735447350425317\n",
            "Error: 0.009117233405426495 \n",
            "\n",
            "Prediction: -0.002858835788034024\n",
            "Prediction: 0.9855260569025094\n",
            "Prediction: -0.06358841060413677\n",
            "Prediction: 1.05752842286588\n",
            "Prediction: 0.9832740020092452\n",
            "Prediction: -0.004313918034364962\n",
            "Error: 0.00786904226904208 \n",
            "\n",
            "Prediction: -0.003451134427491974\n",
            "Prediction: 0.9873957068535818\n",
            "Prediction: -0.059272877470408075\n",
            "Prediction: 1.0536162524729626\n",
            "Prediction: 0.9851206027353137\n",
            "Prediction: -0.004808501248434842\n",
            "Error: 0.006803273214640502 \n",
            "\n",
            "Prediction: -0.0038468009987478735\n",
            "Prediction: 0.9889620124129692\n",
            "Prediction: -0.05524994626077355\n",
            "Prediction: 1.049970908776931\n",
            "Prediction: 0.9867004228010665\n",
            "Prediction: -0.005112871449710697\n",
            "Error: 0.005889303541837786 \n",
            "\n",
            "Prediction: -0.004090297159768559\n",
            "Prediction: 0.9902806551018011\n",
            "Prediction: -0.051499833441728114\n",
            "Prediction: 1.0465740376293469\n",
            "Prediction: 0.9880596998997442\n",
            "Prediction: -0.0052710974096659285\n",
            "Error: 0.0051029252561172675 \n",
            "\n",
            "Prediction: -0.004216877927732746\n",
            "Prediction: 0.9913965574535352\n",
            "Prediction: -0.048004082062078055\n",
            "Prediction: 1.043408578143574\n",
            "Prediction: 0.9892359385403211\n",
            "Prediction: -0.005318059364078823\n",
            "Error: 0.004424644608684828 \n",
            "\n",
            "Prediction: -0.0042544474912630525\n",
            "Prediction: 0.992346001517791\n",
            "Prediction: -0.044745474990504665\n",
            "Prediction: 1.0404586655589985\n",
            "Prediction: 0.9902596156014837\n",
            "Prediction: -0.005281305317687134\n",
            "Error: 0.0038385124412518303 \n",
            "\n",
            "Prediction: -0.0042250442541497055\n",
            "Prediction: 0.9931583274383705\n",
            "Prediction: -0.041707953394155776\n",
            "Prediction: 1.0377095425371112\n",
            "Prediction: 0.9911555487826897\n",
            "Prediction: -0.005182536193432452\n",
            "Error: 0.0033313054558089675 \n",
            "\n",
            "Prediction: -0.004146028954745959\n",
            "Prediction: 0.9938572955409696\n",
            "Prediction: -0.03887654022599941\n",
            "Prediction: 1.0351474779634813\n",
            "Prediction: 0.9919439948626794\n",
            "Prediction: -0.00503879377425797\n",
            "Error: 0.0028919416227737734 \n",
            "\n",
            "Prediction: -0.004031035019406375\n",
            "Prediction: 0.9944621787695098\n",
            "Prediction: -0.03623726848360008\n",
            "Prediction: 1.032759692455092\n",
            "Prediction: 0.9926415313729495\n",
            "Prediction: -0.004863410672429416\n",
            "Error: 0.002511053608117256 \n",
            "\n",
            "Prediction: -0.003890728537943533\n",
            "Prediction: 0.9949886390193969\n",
            "Prediction: -0.03377711399894662\n",
            "Prediction: 1.0305342898820642\n",
            "Prediction: 0.9932617646389992\n",
            "Prediction: -0.004666769772712614\n",
            "Error: 0.0021806703520253884 \n",
            "\n",
            "Prediction: -0.003733415818170091\n",
            "Prediction: 0.9954494302702878\n",
            "Prediction: -0.03148393251909879\n",
            "Prediction: 1.0284601943056741\n",
            "Prediction: 0.9938158986070053\n",
            "Prediction: -0.004456911151490314\n",
            "Error: 0.0018939739123713475 \n",
            "\n",
            "Prediction: -0.003565528921192253\n",
            "Prediction: 0.9958549628928723\n",
            "Prediction: -0.029346400840475826\n",
            "Prediction: 1.0265270918125804\n",
            "Prediction: 0.9943131920358295\n",
            "Prediction: -0.004240016908292479\n",
            "Error: 0.0016451096996342332 \n",
            "\n",
            "Prediction: -0.0033920135266339822\n",
            "Prediction: 0.9962137566721563\n",
            "Prediction: -0.02735396176499221\n",
            "Prediction: 1.0247253767906936\n",
            "Prediction: 0.9947613261560856\n",
            "Prediction: -0.004020798285770878\n",
            "Error: 0.0014290353984827077 \n",
            "\n",
            "Prediction: -0.003216638628616701\n",
            "Prediction: 0.9965328046163073\n",
            "Prediction: -0.025496772653362886\n",
            "Prediction: 1.0230461022472208\n",
            "Prediction: 0.9951667005089379\n",
            "Prediction: -0.0038028045995257484\n",
            "Error: 0.0012413985592149145 \n",
            "\n",
            "Prediction: -0.003042243679620596\n",
            "Prediction: 0.996817865235065\n",
            "Prediction: -0.023765657359234325\n",
            "Prediction: 1.0214809338160067\n",
            "Prediction: 0.995534671160774\n",
            "Prediction: -0.0035886696105582767\n",
            "Error: 0.0010784359268087556 \n",
            "\n",
            "Prediction: -0.0028709356884466207\n",
            "Prediction: 0.9970736974585198\n",
            "Prediction: -0.022152061336940452\n",
            "Prediction: 1.0200221071408409\n",
            "Prediction: 0.9958697426723416\n",
            "Prediction: -0.0033803078583175654\n",
            "Error: 0.0009368896209360312 \n",
            "\n",
            "Prediction: -0.0027042462866540516\n",
            "Prediction: 0.9973042495523706\n",
            "Prediction: -0.02064800972530455\n",
            "Prediction: 1.018662388355171\n",
            "Prediction: 0.9961757229433927\n",
            "Prediction: -0.0031790709774033414\n",
            "Error: 0.0008139366504753339 \n",
            "\n",
            "Prediction: -0.002543256781922673\n",
            "Prediction: 0.9975128111306469\n",
            "Prediction: -0.019246068219762574\n",
            "Prediction: 1.0173950374076535\n",
            "Prediction: 0.9964558482449631\n",
            "Prediction: -0.0029858720226535913\n",
            "Error: 0.0007071291752624441 \n",
            "\n",
            "Prediction: -0.002388697618122871\n",
            "Prediction: 0.9977021355600483\n",
            "Prediction: -0.01793930655497516\n",
            "Prediction: 1.0162137740080082\n",
            "Prediction: 0.9967128843019345\n",
            "Prediction: -0.0028012842268006904\n",
            "Error: 0.0006143435674831474 \n",
            "\n",
            "Prediction: -0.0022410273814405524\n",
            "Prediction: 0.9978745386023716\n",
            "Prediction: -0.016721264429884947\n",
            "Prediction: 1.0151127459893812\n",
            "Prediction: 0.9969492081270097\n",
            "Prediction: -0.0026256193329783125\n",
            "Error: 0.00053373677328488 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usAsmfXFUf4n"
      },
      "source": [
        "#### Full, batch, and stochastic gradient descent\n",
        "\n",
        "Stochastic gradient descent: updates weights one example\n",
        "at a time.\n",
        "\n",
        "(Full) gradient descent: updates weights one dataset at a time.\n",
        "\n",
        "Batch gradient descent: updates weights after n examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J515fN8XU31k"
      },
      "source": [
        "#### Learning indirect correlation\n",
        "\n",
        "If your data doesn’t have correlation, create intermediate data\n",
        "that does. (means create hidden layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ6oG0l6VH7x"
      },
      "source": [
        "#### Stacking neural networks:\n",
        "\n",
        "The output of the first lower network (layer_0 to layer_1) is the input to the second upper neural network (layer_1 to layer_2). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSKVoIutV3yB"
      },
      "source": [
        "#### sometimes correlation (non linear)\n",
        "Turn off the node when the value would be below 0.\n",
        "\n",
        "By turning off any middle node whenever it would be negative, you allow the network to sometimes subscribe to correlation from various inputs. This is impossible for two-layer neural networks, thus adding power to three-layer nets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn0-qjnfijEj",
        "outputId": "41ed5c42-3288-46df-f707-665cd0254173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Backpropagation in code\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "def relu(x):\n",
        "  return (x > 0) * x\n",
        "\n",
        "def relu2deriv(output):\n",
        "  return output>0\n",
        "\n",
        "alpha = 0.2\n",
        "hidden_size = 4\n",
        "\n",
        "streetlights = np.array([[1,0,1],\n",
        "                        [0,1,1],\n",
        "                        [0,0,1],\n",
        "                        [1,1,1]]) # (4 * 3) matrix\n",
        "walk_vs_stop = np.array([[1,1,0,0]]).T # (1 * 4) matrix\n",
        "\n",
        "weights_0_1 = 2*np.random.random((3,hidden_size)) - 1 # (3 * 4) matrix\n",
        "weights_1_2 = 2*np.random.random((hidden_size,1)) - 1 # (4 * 1) matrix\n",
        "\n",
        "for i in range(60):\n",
        "  layer_2_error = 0\n",
        "  for j in range(len(streetlights)):\n",
        "    layer_0 = streetlights[j:j+1] # (1 * 3) matrix\n",
        "    layer_1 = relu(np.dot(layer_0, weights_0_1)) # (1 * 4) matrix\n",
        "    layer_2 = np.dot(layer_1, weights_1_2) # (1 * 1) matrix\n",
        "\n",
        "    layer_2_error += np.sum((layer_2 - walk_vs_stop[j:j+1]) ** 2) # (4 * 1) matrix\n",
        "\n",
        "    layer_2_delta = (walk_vs_stop[j:j+1] - layer_2) # (4 * 1) matrix\n",
        "    layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
        "\n",
        "    weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "    weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "    if(i % 10 == 9):\n",
        "      print(\"Error: {}\".format(layer_2_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.02317222265722177\n",
            "Error: 0.37697998088916795\n",
            "Error: 0.5585446349508787\n",
            "Error: 0.6342311598444467\n",
            "Error: 6.583974603752558e-05\n",
            "Error: 0.18340014797885185\n",
            "Error: 0.31497070417381795\n",
            "Error: 0.35838407676317513\n",
            "Error: 1.2854807174765666e-14\n",
            "Error: 0.032716692228431515\n",
            "Error: 0.07944050755997109\n",
            "Error: 0.0830183113303298\n",
            "Error: 2.438025114683471e-24\n",
            "Error: 0.0016192127634249867\n",
            "Error: 0.006448232304230192\n",
            "Error: 0.006467054957103705\n",
            "Error: 0.0\n",
            "Error: 6.299054636709449e-05\n",
            "Error: 0.0003292669000750734\n",
            "Error: 0.0003292669000750734\n",
            "Error: 0.0\n",
            "Error: 2.8586146897158e-06\n",
            "Error: 1.5055622665134859e-05\n",
            "Error: 1.5055622665134859e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcsIbmxCy6N"
      },
      "source": [
        "### Chapter 8:\n",
        "#### Learning signal and ignoring noise: introduction to regularization and batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9UPRN3xrdo6",
        "outputId": "3829f58d-c115-4365-f79a-eb8e75c02b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys, numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "images, labels = (x_train[0:1000].reshape(1000, 28*28)/255, y_train[0:1000])\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "\n",
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images = x_test.reshape(len(x_test),28*28)/255\n",
        "test_labels = np.zeros((len(y_test),10))\n",
        "\n",
        "for i,l in enumerate(y_test):\n",
        "  test_labels[i][l] = 1\n",
        "\n",
        "np.random.seed(1)\n",
        "relu = lambda x:(x>=0) * x\n",
        "relu2deriv = lambda x: x>=0\n",
        "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
        "\n",
        "for j in range(iterations):\n",
        "  error, correct_cnt = (0.0, 0)\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    layer_0 = images[i:i+1]\n",
        "    layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
        "    layer_2 = np.dot(layer_1, weights_1_2)\n",
        "    error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
        "    correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "    \n",
        "    layer_2_delta = (labels[i:i+1] - layer_2)\n",
        "    layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
        "\n",
        "    weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
        "    weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "  sys.stdout.write(\"\\r\"+ \" I:\"+str(j)+ \" Error:\" + str(error/float(len(images)))[0:5] + \" Correct:\" + str(correct_cnt/float(len(images))))\n",
        "\n",
        "\n",
        "  if(j%10 == 0 or j == iterations-1):\n",
        "    error_test, correct_cnt_t = (0.0, 0)\n",
        "\n",
        "    for i in range(len(test_images)):\n",
        "      layer_0 = test_images[i:i+1]\n",
        "      layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "      layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "      error_test += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "      correct_cnt_t += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "    sys.stdout.write(\" Test-Err:\" + str(error_test/float(len(test_images)))[0:5] + \" Test-Acc:\" + str(correct_cnt_t/float(len(test_images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " I:349 Error:0.108 Correct:1.0 Test-Err:0.653 Test-Acc:0.7073"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEJerHPNDWPJ",
        "outputId": "453710a6-69f3-4bc6-e59f-5d2fe131d44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "streetlights = np.array([[1,0,1],\n",
        "                         [0,1,1],\n",
        "                         [0,0,1],\n",
        "                         [1,1,1]])\n",
        "walk_vs_stop = np.array([1,1,0,0]).T\n",
        "\n",
        "relu = lambda x: (x>0) * x\n",
        "relu2deriv = lambda x: x>0\n",
        "\n",
        "alpha = 0.2\n",
        "hidden_size = 4\n",
        "\n",
        "weights_0_1 = 2*np.random.random((3, hidden_size)) - 1\n",
        "weights_1_2 = 2*np.random.random((hidden_size, 1)) - 1\n",
        "\n",
        "for iteration in range(60):\n",
        "  layer_2_error=0\n",
        "  for i in range(len(streetlights)):\n",
        "    layer_0 = streetlights[i:i+1]\n",
        "    layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
        "    layer_2 = np.dot(layer_1, weights_1_2)\n",
        "\n",
        "    layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
        "    layer_2_delta = layer_2 - walk_vs_stop[i:i+1]\n",
        "\n",
        "    layer_1_delta = np.dot(layer_2_delta, weights_1_2.T) * relu2deriv(layer_1)\n",
        "\n",
        "    weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
        "    weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "  if(iteration % 10 == 9):\n",
        "    print(\"Error:\" + str(layer_2_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error:0.6342311598444467\n",
            "Error:0.35838407676317513\n",
            "Error:0.0830183113303298\n",
            "Error:0.006467054957103705\n",
            "Error:0.0003292669000750734\n",
            "Error:1.5055622665134859e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZMmJc32YUuK"
      },
      "source": [
        "#### Chapter 8 : code (without dropout)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x52PcP4LD52O"
      },
      "source": [
        "# chapter 8 (without dropout)\n",
        "import sys, numpy as np\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrfhTajUEppv"
      },
      "source": [
        "# load_data() return Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfi13uChjXqu",
        "outputId": "a0771fcd-0a0d-460b-f854-f84ae8e29e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXrSZm61lkYy",
        "outputId": "d22d4fa8-a9be-401e-f48b-81cb4fb97f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "\n",
        "one_hot_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEs46s6knZw2",
        "outputId": "2b393960-8e31-44b2-8641-c8520d216cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# this part is confusing, labels has numbers from 0-9 for 1000 rows, this part is creating a 1000*10 matrix where for each row it's putting a 1 in place of a 0 in 1000*10 matrix\n",
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdRy79FO7LHq",
        "outputId": "5da082b6-415e-4084-ffe2-0df3b798ac7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n",
            " 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n",
            " 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1 5 7 1 7 1 1 6 3 0 2 9\n",
            " 3 1 1 0 4 9 2 0 0 2 0 2 7 1 8 6 4 1 6 3 4 5 9 1 3 3 8 5 4 7 7 4 2 8 5 8 6\n",
            " 7 3 4 6 1 9 9 6 0 3 7 2 8 2 9 4 4 6 4 9 7 0 9 2 9 5 1 5 9 1 2 3 2 3 5 9 1\n",
            " 7 6 2 8 2 2 5 0 7 4 9 7 8 3 2 1 1 8 3 6 1 0 3 1 0 0 1 7 2 7 3 0 4 6 5 2 6\n",
            " 4 7 1 8 9 9 3 0 7 1 0 2 0 3 5 4 6 5 8 6 3 7 5 8 0 9 1 0 3 1 2 2 3 3 6 4 7\n",
            " 5 0 6 2 7 9 8 5 9 2 1 1 4 4 5 6 4 1 2 5 3 9 3 9 0 5 9 6 5 7 4 1 3 4 0 4 8\n",
            " 0 4 3 6 8 7 6 0 9 7 5 7 2 1 1 6 8 9 4 1 5 2 2 9 0 3 9 6 7 2 0 3 5 4 3 6 5\n",
            " 8 9 5 4 7 4 2 7 3 4 8 9 1 9 2 8 7 9 1 8 7 4 1 3 1 1 0 2 3 9 4 9 2 1 6 8 4\n",
            " 7 7 4 4 9 2 5 7 2 4 4 2 1 9 7 2 8 7 6 9 2 2 3 8 1 6 5 1 1 0 2 6 4 5 8 3 1\n",
            " 5 1 9 2 7 4 4 4 8 1 5 8 9 5 6 7 9 9 3 7 0 9 0 6 6 2 3 9 0 7 5 4 8 0 9 4 1\n",
            " 2 8 7 1 2 6 1 0 3 0 1 1 8 2 0 3 9 4 0 5 0 6 1 7 7 8 1 9 2 0 5 1 2 2 7 3 5\n",
            " 4 9 7 1 8 3 9 6 0 3 1 1 2 6 3 5 7 6 8 3 9 5 8 5 7 6 1 1 3 1 7 5 5 5 2 5 8\n",
            " 7 0 9 7 7 5 0 9 0 0 8 9 2 4 8 1 6 1 6 5 1 8 3 4 0 5 5 8 3 6 2 3 9 2 1 1 5\n",
            " 2 1 3 2 8 7 3 7 2 4 6 9 7 2 4 2 8 1 1 3 8 4 0 6 5 9 3 0 9 2 4 7 1 2 9 4 2\n",
            " 6 1 8 9 0 6 6 7 9 9 8 0 1 4 4 6 7 1 5 7 0 3 5 8 4 7 1 2 5 9 5 6 7 5 9 8 8\n",
            " 3 6 9 7 0 7 5 7 1 1 0 7 9 2 3 7 3 2 4 1 6 2 7 5 5 7 4 0 2 6 3 6 4 0 4 2 6\n",
            " 0 0 0 0 3 1 6 2 2 3 1 4 1 5 4 6 4 7 2 8 7 9 2 0 5 1 4 2 8 3 2 4 1 5 4 6 0\n",
            " 7 9 8 4 9 8 0 1 1 0 2 2 3 2 4 4 5 8 6 5 7 7 8 8 9 7 4 7 3 2 0 8 6 8 6 1 6\n",
            " 8 9 4 0 9 0 4 1 5 4 7 5 3 7 4 9 8 5 8 6 3 8 6 9 9 1 8 3 5 8 6 5 9 7 2 5 0\n",
            " 8 5 1 1 0 9 1 8 6 7 0 9 3 0 8 8 9 6 7 8 4 7 5 9 2 6 7 4 5 9 2 3 1 6 3 9 2\n",
            " 2 5 6 8 0 7 7 1 9 8 7 0 9 9 4 6 2 8 5 1 4 1 5 5 1 7 3 6 4 3 2 5 6 4 4 0 4\n",
            " 4 6 7 2 4 3 3 8 0 0 3 2 2 9 8 2 3 7 0 1 1 0 2 3 3 8 4 3 5 7 6 4 7 7 8 5 9\n",
            " 7 0 3 1 6 2 4 3 4 4 7 5 9 6 9 0 7 1 4 2 7 3 6 7 5 8 4 5 5 2 7 1 1 5 6 8 5\n",
            " 8 4 0 7 9 9 2 9 7 7 8 7 4 2 6 9 1 7 0 6 4 2 5 7 0 7 1 0 3 7 6 5 0 6 1 5 1\n",
            " 7 8 5 0 3 4 7 7 5 7 8 6 9 3 8 6 1 0 9 7 1 3 0 5 6 4 4 2 4 4 3 1 7 7 6 0 3\n",
            " 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbMdGA1_BL7R",
        "outputId": "572a274d-20b9-4620-dd3a-e39b9ca38d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "labels = one_hot_labels\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZfGz38PBcxp"
      },
      "source": [
        "test_images, test_labels = (x_test.reshape(len(x_test), 28*28), np.zeros((len(y_test),10)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2md7PyhCrSl"
      },
      "source": [
        "for i,l in enumerate(y_test):\n",
        "  test_labels[i][l] = 1\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "relu = lambda x : (x>=0) * x\n",
        "relu2deriv = lambda x: x>=0\n",
        "\n",
        "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size)) - 0.1 # 784*40 size matrix\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1 # 40*10 size matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzBZz3SrH-Wt",
        "outputId": "cdcac899-7546-489b-87f5-777a28249991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for j in range(iterations):\n",
        "  error, correct_cnt = (0.0, 0)\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    layer_0 = images[i:i+1]\n",
        "    layer_1 = relu(layer_0.dot(weights_0_1))\n",
        "    layer_2 = layer_1.dot(weights_1_2)\n",
        "\n",
        "    error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
        "    correct_cnt += int(np.argmax(labels[i:i+1]) == np.argmax(layer_2))\n",
        "\n",
        "    layer_2_delta = (labels[i:i+1] - layer_2) # 1*10\n",
        "    layer_1_delta = (layer_2_delta.dot(weights_1_2.T)) * relu2deriv(layer_1) # (1*10).dot(40*10.T)*(1*40) = 1*40\n",
        "\n",
        "    weights_1_2 += alpha * layer_1.T.dot(layer_2_delta) # scalar*(1*40.T).dot(1*10) = 40*10\n",
        "    weights_0_1 += alpha * layer_0.T.dot(layer_1_delta) # scalar*(1*784.T).dot(1*40) = 784*40\n",
        "\n",
        "  sys.stdout.write(\"\\r\"+ \" I:\"+str(j)+ \" Error:\" + str(error/float(len(images)))[0:5] + \" Correct:\" + str(correct_cnt/float(len(images))))\n",
        "  \n",
        "  if(j%10 == 0 or j == iterations-1):\n",
        "    error_test, correct_cnt_t = 0.0, 0\n",
        "\n",
        "    for i in range(len(test_images)):\n",
        "      layer_0 = test_images[i:i+1]\n",
        "      layer_1 = layer_0.dot(weights_0_1)\n",
        "      layer_2 = layer_1.dot(weights_1_2)\n",
        "\n",
        "      error_test += np.sum((layer_2 - test_labels[i:i+1])**2)\n",
        "      correct_cnt_t += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "    sys.stdout.write(\" Test-Err:\" + str(error_test/float(len(test_images)))[0:5] + \" Test-Acc:\" + str(correct_cnt_t/float(len(test_images))))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " I:349 Error:0.108 Correct:1.0 Test-Err:15948 Test-Acc:0.3834"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJuzoHSaYwM_"
      },
      "source": [
        "#### Dropout in code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ2iyrsEJffb",
        "outputId": "104d5049-a1b5-4846-c27f-971db153cdcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "import sys, numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "images, labels = (x_train[0:1000].reshape(1000, 28*28)/255, y_train[0:1000])\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "\n",
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images, test_labels = (x_test.reshape(len(x_test), 28*28)/255, np.zeros((len(y_test), 10)))\n",
        "\n",
        "for i,l in enumerate(y_test):\n",
        "  test_labels[i][l] = 1\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "relu = lambda x: (x>=0) * x\n",
        "relu2deriv = lambda x: x>=0\n",
        "\n",
        "alpha, iterations, hidden_size = (0.005, 300, 100)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size)) - 0.1 # 784*100\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1 # (100*10)\n",
        "\n",
        "for j in range(iterations):\n",
        "  error, correct_cnt = (0.0, 0)\n",
        "  for i in range(len(images)):\n",
        "    layer_0 = images[i:i+1] # (1*784)\n",
        "    layer_1 = relu(layer_0.dot(weights_0_1)) # (1*100)\n",
        "    dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "    layer_1 *= dropout_mask * 2\n",
        "    layer_2 = layer_1.dot(weights_1_2)\n",
        "\n",
        "    error += np.sum((layer_2 - labels[i:i+1]) ** 2)\n",
        "    correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
        "\n",
        "    layer_2_delta = (labels[i:i+1] - layer_2) # (1*10) - (1*10)\n",
        "    layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1) # (1*10).dot(100*10.T)*relu2deriv(1*100) = (1*100)\n",
        "    layer_1_delta *= dropout_mask\n",
        "\n",
        "    weights_1_2 += alpha*(layer_1.T.dot(layer_2_delta)) # scalar * (100*1).dot(1*10) = (100*10)\n",
        "    weights_0_1 += alpha*(layer_0.T.dot(layer_1_delta)) # scalar*(784*1).dot(1*100) = (784*100)\n",
        "\n",
        "  if(j%10 == 0):\n",
        "    test_error = 0.0\n",
        "    test_correct_cnt = 0\n",
        "\n",
        "    for i in range(len(test_images)):\n",
        "      layer_0 = test_images[i:i+1]\n",
        "      layer_1 = relu(layer_0.dot(weights_0_1)) # why activation function was used for test data?\n",
        "      layer_2 = layer_1.dot(weights_1_2)\n",
        "\n",
        "      test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "      test_correct_cnt += int(np.argmax(test_labels[i:i+1]) == np.argmax(layer_2))\n",
        "\n",
        "    sys.stdout.write(\"\\n\" +\n",
        "                     \"I:\" + str(j) +\n",
        "                     \" Test-Err:\"+str(test_error/float(len(test_images)))[0:5] +\n",
        "                     \" Test-Acc:\"+str(test_correct_cnt/float(len(test_images))) +\n",
        "                     \" Train-Err:\"+str(error/float(len(images)))[0:5] +\n",
        "                     \" Train-Acc:\"+str(correct_cnt/float(len(images))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I:0 Test-Err:0.641 Test-Acc:0.6333 Train-Err:0.891 Train-Acc:0.413\n",
            "I:10 Test-Err:0.458 Test-Acc:0.787 Train-Err:0.472 Train-Acc:0.764\n",
            "I:20 Test-Err:0.415 Test-Acc:0.8133 Train-Err:0.430 Train-Acc:0.809\n",
            "I:30 Test-Err:0.421 Test-Acc:0.8114 Train-Err:0.415 Train-Acc:0.811\n",
            "I:40 Test-Err:0.419 Test-Acc:0.8112 Train-Err:0.413 Train-Acc:0.827\n",
            "I:50 Test-Err:0.409 Test-Acc:0.8133 Train-Err:0.392 Train-Acc:0.836\n",
            "I:60 Test-Err:0.412 Test-Acc:0.8236 Train-Err:0.402 Train-Acc:0.836\n",
            "I:70 Test-Err:0.412 Test-Acc:0.8033 Train-Err:0.383 Train-Acc:0.857\n",
            "I:80 Test-Err:0.410 Test-Acc:0.8054 Train-Err:0.386 Train-Acc:0.854\n",
            "I:90 Test-Err:0.411 Test-Acc:0.8144 Train-Err:0.376 Train-Acc:0.868\n",
            "I:100 Test-Err:0.411 Test-Acc:0.7903 Train-Err:0.369 Train-Acc:0.864\n",
            "I:110 Test-Err:0.411 Test-Acc:0.8003 Train-Err:0.371 Train-Acc:0.868\n",
            "I:120 Test-Err:0.402 Test-Acc:0.8046 Train-Err:0.353 Train-Acc:0.857\n",
            "I:130 Test-Err:0.408 Test-Acc:0.8091 Train-Err:0.352 Train-Acc:0.867\n",
            "I:140 Test-Err:0.405 Test-Acc:0.8083 Train-Err:0.355 Train-Acc:0.885\n",
            "I:150 Test-Err:0.404 Test-Acc:0.8107 Train-Err:0.342 Train-Acc:0.883\n",
            "I:160 Test-Err:0.399 Test-Acc:0.8146 Train-Err:0.361 Train-Acc:0.876\n",
            "I:170 Test-Err:0.404 Test-Acc:0.8074 Train-Err:0.344 Train-Acc:0.889\n",
            "I:180 Test-Err:0.399 Test-Acc:0.807 Train-Err:0.333 Train-Acc:0.892\n",
            "I:190 Test-Err:0.407 Test-Acc:0.8066 Train-Err:0.335 Train-Acc:0.898\n",
            "I:200 Test-Err:0.405 Test-Acc:0.8036 Train-Err:0.347 Train-Acc:0.893\n",
            "I:210 Test-Err:0.405 Test-Acc:0.8034 Train-Err:0.336 Train-Acc:0.894\n",
            "I:220 Test-Err:0.402 Test-Acc:0.8067 Train-Err:0.325 Train-Acc:0.896\n",
            "I:230 Test-Err:0.404 Test-Acc:0.8091 Train-Err:0.321 Train-Acc:0.894\n",
            "I:240 Test-Err:0.415 Test-Acc:0.8091 Train-Err:0.332 Train-Acc:0.898\n",
            "I:250 Test-Err:0.395 Test-Acc:0.8182 Train-Err:0.320 Train-Acc:0.899\n",
            "I:260 Test-Err:0.390 Test-Acc:0.8204 Train-Err:0.321 Train-Acc:0.899\n",
            "I:270 Test-Err:0.382 Test-Acc:0.8194 Train-Err:0.312 Train-Acc:0.906\n",
            "I:280 Test-Err:0.396 Test-Acc:0.8208 Train-Err:0.317 Train-Acc:0.9\n",
            "I:290 Test-Err:0.399 Test-Acc:0.8181 Train-Err:0.301 Train-Acc:0.908"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efkJ6e6hMuoN"
      },
      "source": [
        "#### Dropout in code (with batch gradient descent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY2BlbNT2CtY",
        "outputId": "b90f47d2-968f-485b-896e-04488b46b695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "import sys, numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "images, labels = (x_train[0:1000].reshape(1000, 28*28)/255,y_train[0:1000])\n",
        "\n",
        "one_hot_labels = np.zeros((len(labels),10))\n",
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images, test_labels = (x_test.reshape(len(x_test), 28*28)/255, np.zeros((len(y_test),10)))\n",
        "\n",
        "for i,l in enumerate(y_test):\n",
        "  test_labels[i][l] = 1\n",
        "\n",
        "np.random.seed(1)\n",
        "relu = lambda x: (x>=0) * x\n",
        "relu2deriv = lambda x: x>=0\n",
        "\n",
        "batch_size = 100\n",
        "alpha, iterations = (0.001, 300)\n",
        "pixel_per_image, num_labels, hidden_size = (784, 10, 100)\n",
        "\n",
        "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size)) - 0.1 # (784*100)\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1 # (100*10)\n",
        "\n",
        "for j in range(iterations):\n",
        "  error, correct_cnt = (0.0, 0)\n",
        "  for i in range(int(len(images)/batch_size)):\n",
        "    batch_start, batch_end = ((i*batch_size), ((i+1)*batch_size))\n",
        "    layer_0 = images[batch_start:batch_end] # (100*784)\n",
        "    layer_1 = relu(layer_0.dot(weights_0_1)) # (100*784).dot(784*100) = (100*100)\n",
        "    dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "    layer_1 *= dropout_mask * 2\n",
        "    layer_2 = layer_1.dot(weights_1_2) # (100*100).dot(100*10) = (100*10)\n",
        "\n",
        "    error += np.sum((labels[batch_start:batch_end] - layer_2) ** 2)\n",
        "\n",
        "    for k in range(batch_size):\n",
        "      correct_cnt += int(np.argmax(labels[batch_start:batch_end] == np.argmax(layer_2[k:k+1])))\n",
        "      layer_2_delta = (labels[batch_start:batch_end] - layer_2) / batch_size # ((100*10) - (100*10))/scalar = (100*10)\n",
        "      layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1) # (100*10).dot(100*10.T) * relu2deriv(100*100) = (100*100)\n",
        "      layer_1_delta *= dropout_mask\n",
        "      weights_1_2 += alpha*layer_1.T.dot(layer_2_delta) # scalar*(100*100.T).dot(100*10) = (100*10)\n",
        "      weights_0_1 += alpha*layer_0.T.dot(layer_1_delta) # scalar*(100*784.T).dot(100*100) = (784*100)\n",
        "\n",
        "  if(j%10==0):\n",
        "    test_error, test_correct_cnt = (0.0, 0)\n",
        "    for i in range(len(test_images)):\n",
        "      layer_0 = test_images[i:i+1]\n",
        "      layer_1 = relu(layer_0.dot(weights_0_1))\n",
        "      layer_2 = layer_1.dot(weights_1_2)\n",
        "      test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
        "      test_correct_cnt += int(np.argmax(test_labels[i:i+1]) == np.argmax(layer_2))\n",
        "\n",
        "    sys.stdout.write(\"\\n\" +\n",
        "                     \"I:\" + str(j) +\n",
        "                     \" Test-Err:\"+str(test_error/float(len(test_images)))[0:5] +\n",
        "                     \" Test-Acc:\"+str(test_correct_cnt/float(len(test_images))) +\n",
        "                     \" Train-Err:\"+str(error/float(len(images)))[0:5] +\n",
        "                     \" Train-Acc:\"+str(correct_cnt/float(len(images))))\n",
        "      "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I:0 Test-Err:0.815 Test-Acc:0.3832 Train-Err:1.284 Train-Acc:0.362\n",
            "I:10 Test-Err:0.568 Test-Acc:0.7173 Train-Err:0.591 Train-Acc:0.53\n",
            "I:20 Test-Err:0.510 Test-Acc:0.7571 Train-Err:0.532 Train-Acc:0.438\n",
            "I:30 Test-Err:0.485 Test-Acc:0.7793 Train-Err:0.498 Train-Acc:0.331\n",
            "I:40 Test-Err:0.468 Test-Acc:0.7877 Train-Err:0.489 Train-Acc:0.309\n",
            "I:50 Test-Err:0.458 Test-Acc:0.793 Train-Err:0.468 Train-Acc:0.28\n",
            "I:60 Test-Err:0.452 Test-Acc:0.7995 Train-Err:0.452 Train-Acc:0.305\n",
            "I:70 Test-Err:0.446 Test-Acc:0.803 Train-Err:0.453 Train-Acc:0.269\n",
            "I:80 Test-Err:0.451 Test-Acc:0.7968 Train-Err:0.457 Train-Acc:0.314\n",
            "I:90 Test-Err:0.447 Test-Acc:0.795 Train-Err:0.454 Train-Acc:0.252\n",
            "I:100 Test-Err:0.448 Test-Acc:0.793 Train-Err:0.447 Train-Acc:0.284\n",
            "I:110 Test-Err:0.441 Test-Acc:0.7943 Train-Err:0.426 Train-Acc:0.232\n",
            "I:120 Test-Err:0.442 Test-Acc:0.7966 Train-Err:0.431 Train-Acc:0.246\n",
            "I:130 Test-Err:0.441 Test-Acc:0.7906 Train-Err:0.434 Train-Acc:0.254\n",
            "I:140 Test-Err:0.447 Test-Acc:0.7874 Train-Err:0.437 Train-Acc:0.227\n",
            "I:150 Test-Err:0.443 Test-Acc:0.7899 Train-Err:0.414 Train-Acc:0.222\n",
            "I:160 Test-Err:0.438 Test-Acc:0.797 Train-Err:0.427 Train-Acc:0.233\n",
            "I:170 Test-Err:0.440 Test-Acc:0.7884 Train-Err:0.418 Train-Acc:0.224\n",
            "I:180 Test-Err:0.436 Test-Acc:0.7935 Train-Err:0.407 Train-Acc:0.234\n",
            "I:190 Test-Err:0.434 Test-Acc:0.7935 Train-Err:0.410 Train-Acc:0.201\n",
            "I:200 Test-Err:0.435 Test-Acc:0.7972 Train-Err:0.416 Train-Acc:0.212\n",
            "I:210 Test-Err:0.434 Test-Acc:0.7923 Train-Err:0.409 Train-Acc:0.209\n",
            "I:220 Test-Err:0.433 Test-Acc:0.8032 Train-Err:0.396 Train-Acc:0.259\n",
            "I:230 Test-Err:0.431 Test-Acc:0.8036 Train-Err:0.393 Train-Acc:0.227\n",
            "I:240 Test-Err:0.430 Test-Acc:0.8047 Train-Err:0.397 Train-Acc:0.263\n",
            "I:250 Test-Err:0.429 Test-Acc:0.8028 Train-Err:0.386 Train-Acc:0.256\n",
            "I:260 Test-Err:0.431 Test-Acc:0.8038 Train-Err:0.394 Train-Acc:0.272\n",
            "I:270 Test-Err:0.428 Test-Acc:0.8014 Train-Err:0.384 Train-Acc:0.294\n",
            "I:280 Test-Err:0.430 Test-Acc:0.8067 Train-Err:0.401 Train-Acc:0.278\n",
            "I:290 Test-Err:0.428 Test-Acc:0.7975 Train-Err:0.383 Train-Acc:0.253"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6lg9RuqAiVH"
      },
      "source": [
        "### Chapter 9: Activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icJ_DvsWAm91"
      },
      "source": [
        "#### MNIST with tanh and softmax:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhL_enevUnih",
        "outputId": "f33d4a60-6094-429a-f716-54897ac5a38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "import sys, numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "np.random.seed(1)\n",
        "\n",
        "images, labels = (train_x[0:1000].reshape(1000, 28*28)/255, train_y[0:1000])\n",
        "one_hot_labels = np.zeros((len(labels), 10))\n",
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels\n",
        "\n",
        "test_images, test_labels = (test_x.reshape(len(test_x), 28*28), np.zeros((len(test_y), 10)))\n",
        "for i,l in enumerate(test_y):\n",
        "  test_labels[i][l] = 1\n",
        "\n",
        "tanh = lambda x: np.tanh(x)\n",
        "tanh2deriv = lambda x: 1 - (x ** 2)\n",
        "\n",
        "def softmax(x):\n",
        "  temp = np.exp(x)\n",
        "  return temp/np.sum(temp, axis=1, keepdims=True)\n",
        "\n",
        "alpha, iterations, hidden_size = (2, 300, 100)\n",
        "pixels_per_image, num_labels = (784, 10)\n",
        "batch_size = 100\n",
        "\n",
        "weights_0_1 = 0.02*np.random.random((pixels_per_image, hidden_size)) - 0.01 # (784*100)\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1 # (100*10)\n",
        "\n",
        "for j in range(iterations):\n",
        "  correct_cnt = 0\n",
        "  for i in range(int(len(images)/batch_size)):\n",
        "    batch_start, batch_end = (i*batch_size,(i+1)*batch_size)\n",
        "    layer_0 = images[batch_start:batch_end] # (100*784)\n",
        "    layer_1 = tanh(layer_0.dot(weights_0_1)) # activationFn(100*784.dot(784*100)) = (100*100)\n",
        "    dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
        "    layer_1 *= dropout_mask * 2\n",
        "    layer_2 = softmax(layer_1.dot(weights_1_2)) # activationFn(100*100.dot(100*10)) = (100*10)\n",
        "\n",
        "    for k in range(batch_size):\n",
        "      correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1])) # need to understand this line\n",
        "      layer_2_delta = (labels[batch_start:batch_end] - layer_2[k:k+1])/(batch_size*layer_2.shape[0]) # (100*10) need to understand this line\n",
        "      layer_1_delta = (layer_2_delta.dot(weights_1_2.T)) * tanh2deriv(layer_1) # (100*10.dot(100*10.T)*derivative(100*100)) = (100*100)\n",
        "      layer_1_delta *= dropout_mask\n",
        "\n",
        "      weights_1_2 += alpha*layer_1.T.dot(layer_2_delta) # scalar*(100*100.T).dot(100*10) = (100*10)\n",
        "      weights_0_1 += alpha*layer_0.T.dot(layer_1_delta) # scalar*(100*784.T).dot(100*100) = (784*100)\n",
        "\n",
        "  test_correct_cnt = 0\n",
        "  for i in range(len(test_images)):\n",
        "    layer_0 = test_images[i:i+1]\n",
        "    layer_1 = tanh(layer_0.dot(weights_0_1))\n",
        "    layer_2 = layer_1.dot(weights_1_2)\n",
        "    test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
        "\n",
        "  if(j%10 == 0):\n",
        "    sys.stdout.write(\"\\n\" + \"I:\"+str(j)+\n",
        "                     \" Test_Acc:\" +str(test_correct_cnt/float(len(test_images)))+\n",
        "                     \" Train_Acc:\"+str(correct_cnt/float(len(images)))\n",
        "                     )\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I:0 Test_Acc:0.0974 Train_Acc:0.196\n",
            "I:10 Test_Acc:0.2115 Train_Acc:0.136\n",
            "I:20 Test_Acc:0.1254 Train_Acc:0.084\n",
            "I:30 Test_Acc:0.1046 Train_Acc:0.098\n",
            "I:40 Test_Acc:0.1319 Train_Acc:0.115\n",
            "I:50 Test_Acc:0.1881 Train_Acc:0.138\n",
            "I:60 Test_Acc:0.1201 Train_Acc:0.128\n",
            "I:70 Test_Acc:0.2217 Train_Acc:0.159\n",
            "I:80 Test_Acc:0.1891 Train_Acc:0.135\n",
            "I:90 Test_Acc:0.0989 Train_Acc:0.098\n",
            "I:100 Test_Acc:0.1585 Train_Acc:0.127\n",
            "I:110 Test_Acc:0.1434 Train_Acc:0.136\n",
            "I:120 Test_Acc:0.0833 Train_Acc:0.091\n",
            "I:130 Test_Acc:0.128 Train_Acc:0.136\n",
            "I:140 Test_Acc:0.056 Train_Acc:0.095\n",
            "I:150 Test_Acc:0.123 Train_Acc:0.127\n",
            "I:160 Test_Acc:0.1282 Train_Acc:0.132\n",
            "I:170 Test_Acc:0.1511 Train_Acc:0.136\n",
            "I:180 Test_Acc:0.1858 Train_Acc:0.155\n",
            "I:190 Test_Acc:0.1135 Train_Acc:0.103\n",
            "I:200 Test_Acc:0.1704 Train_Acc:0.13\n",
            "I:210 Test_Acc:0.2617 Train_Acc:0.167\n",
            "I:220 Test_Acc:0.0904 Train_Acc:0.109\n",
            "I:230 Test_Acc:0.1513 Train_Acc:0.134\n",
            "I:240 Test_Acc:0.1219 Train_Acc:0.135\n",
            "I:250 Test_Acc:0.1153 Train_Acc:0.112\n",
            "I:260 Test_Acc:0.1413 Train_Acc:0.118"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "I:270 Test_Acc:0.098 Train_Acc:0.097\n",
            "I:280 Test_Acc:0.098 Train_Acc:0.097\n",
            "I:290 Test_Acc:0.098 Train_Acc:0.097"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v2LRwaAA8sn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}